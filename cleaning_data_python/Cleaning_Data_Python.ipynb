{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Cleaning Data with Python_\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnóstico\n",
    "\n",
    "Antes de realizar cualquier trabajo sobre nuestros datos es importante tomarnos un tiempo para explorar su naturaleza. Hay ciertos puntos que, por lo general, debemos tomar en cuenta sobre nuestros datos:\n",
    "\n",
    "* Nuestro dataset puede tener inconsistencias en el nombre de sus atributos (columnas), es decir; _–Probablemente los títulos tengan simbolos, espacios en blanco, caracteres erroneos, etc, etc...–_ todo aquello que impida una correcta identificación de ellas.\n",
    "\n",
    "* \"Missin Data\" o datos omitidos, por alguna razón, deben ser identificados y localizados.\n",
    "\n",
    "* \"Outliers\" suelen ser un proble potencial a la hora de trabajar con nuestros datos. Para ello es necesario conocer más sobre la naturaleza de nuestro dataset para después clasificarlos y entender _–¿ Cuales pueden ser un verdadero problema o cuales no ?.–_\n",
    "\n",
    "* Registros duplicados.\n",
    "\n",
    "* La asignación de formatos erroneos en los registros de los atributos (columnas) pueden traernos valores equivocados a la hora de procesarlos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITNO</th>\n",
       "      <th>MAP_SYMBOL</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LITH1</th>\n",
       "      <th>LITH2</th>\n",
       "      <th>LITH3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*56</td>\n",
       "      <td>Dne</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Northeast Shale</td>\n",
       "      <td>Devonian</td>\n",
       "      <td>Shale</td>\n",
       "      <td>Siltstone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*55</td>\n",
       "      <td>Dg</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Girard Shale</td>\n",
       "      <td>Devonian</td>\n",
       "      <td>Argillaceous shale</td>\n",
       "      <td>Siltstone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*54</td>\n",
       "      <td>Dch</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Chadakoin Formation</td>\n",
       "      <td>Devonian</td>\n",
       "      <td>Siltstone</td>\n",
       "      <td>Sandstone</td>\n",
       "      <td>Shale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*1</td>\n",
       "      <td>Qs</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Sands of Presque Isle</td>\n",
       "      <td>Quaternary</td>\n",
       "      <td>Sand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UNITNO MAP_SYMBOL        STATE                   NAME         AGE  \\\n",
       "0    *56        Dne  PENSILVANIA        Northeast Shale    Devonian   \n",
       "1    *55         Dg  PENSILVANIA           Girard Shale    Devonian   \n",
       "2    *54        Dch  PENSILVANIA    Chadakoin Formation    Devonian   \n",
       "3     *1         Qs  PENSILVANIA  Sands of Presque Isle  Quaternary   \n",
       "4    *28        NaN  PENSILVANIA                    NaN         NaN   \n",
       "\n",
       "                LITH1      LITH2  LITH3  \n",
       "0               Shale  Siltstone    NaN  \n",
       "1  Argillaceous shale  Siltstone    NaN  \n",
       "2           Siltstone  Sandstone  Shale  \n",
       "3                Sand        NaN    NaN  \n",
       "4                 NaN        NaN    NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('pagpoly.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseamos imprimir cierta parte de nuestro dataset, por que así lo hemos deseado, podemos echar mano de las siguientes métodos:\n",
    "\n",
    "* `DataFrame.head()` nos arrojará los primeros 5 renglones de nuestro dataset.\n",
    "\n",
    "* `DatarFrame.tail()` nos arrijará los últimos 5 renglones de nuestro dataset.\n",
    "\n",
    "* `DataFrame.shape` nos arroja el número de renglones y de columnas de nuestro dataset. Por ejemplo: –_El dataset **df** tiene un \"shape\" **(14478, 7)**. Es decir; que se compone de 14,478 regnglones y 7 atributos (columnas)–._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos de los atributos más importantes en _Pandas_, para un _DataFrame_, son `.columns` e `.info()`. Nos ayudan a identificar errores en los títulos de los atributos, caracteres erroneos o identificar valores omitidos por alguna razón o el tipo de formato en los regitros de los atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNITNO', 'MAP_SYMBOL', 'STATE', 'NAME', 'AGE', 'LITH1', 'LITH2',\n",
       "       'LITH3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14480 entries, 0 to 14479\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   UNITNO      14480 non-null  object\n",
      " 1   MAP_SYMBOL  14476 non-null  object\n",
      " 2   STATE       14480 non-null  object\n",
      " 3   NAME        14474 non-null  object\n",
      " 4   AGE         14476 non-null  object\n",
      " 5   LITH1       14476 non-null  object\n",
      " 6   LITH2       13486 non-null  object\n",
      " 7   LITH3       12213 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 905.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los siguientes ejemplos es necesario aislar los siguiente atributos; `UNITNO`, `NAME` y `AGE` en un nuevo dataframe, al cual llamaremos `df_subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITNO</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*56</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Northeast Shale</td>\n",
       "      <td>Devonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*55</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Girard Shale</td>\n",
       "      <td>Devonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*54</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Chadakoin Formation</td>\n",
       "      <td>Devonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*1</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>Sands of Presque Isle</td>\n",
       "      <td>Quaternary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*28</td>\n",
       "      <td>PENSILVANIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UNITNO        STATE                   NAME         AGE\n",
       "0    *56  PENSILVANIA        Northeast Shale    Devonian\n",
       "1    *55  PENSILVANIA           Girard Shale    Devonian\n",
       "2    *54  PENSILVANIA    Chadakoin Formation    Devonian\n",
       "3     *1  PENSILVANIA  Sands of Presque Isle  Quaternary\n",
       "4    *28  PENSILVANIA                    NaN         NaN"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset=df[['UNITNO','STATE','NAME','AGE']]\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si volvemos a consultar la información de nuestro nuevo dataframe `df_subset` vemos que la columna `UNITNO` tiene un tipo de dato `object`. Esto es por que; _–el signo `*` antepuesto a las cantidades es conciderado como texto, lo cual impide representar a estos atributos como números–._ El siguiente paso será eliminarlos y cambiar el formato a dichos atributos por un caracter numérico.\n",
    "\n",
    "Si observamos el primer dataframe `df` nos encontramos que; la cantidad de objetos para cada atributo es de un total de **14,478**. Pero en los atributos restantes sus registros reportan una cantidad menor. Los registro de de estos atributos se concideran omitidos o sin ningúna representación por el momento. Por ejemplo: `MAP_SYMBOL`, `LITH1`, `LITH2`,`LITH3`... son algunos atributos con registros omitidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14480 entries, 0 to 14479\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   UNITNO  14480 non-null  object\n",
      " 1   STATE   14480 non-null  object\n",
      " 2   NAME    14474 non-null  object\n",
      " 3   AGE     14476 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 452.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_subset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis explotratorio de datos.\n",
    "\n",
    "Hay dos maneras de realizar rapidamente un análisis exploratorio de nuestros datos. Una es contando las frecuencias de los valores únicos para cada registro. La otra es obteniendo estadísticas básicas en los atributos. _Python_ nos permite hacer esto mediante los métodos: `.value_counts(dropna=False)` y `df.describe()`\n",
    "\n",
    "Los siguientes métodos son aplicados para una exploración rápida en el dataset:\n",
    "\n",
    "1.- `DataFrame.column_name.value_counts(dropna=False)` nos arroja el conteo de las frecuencias para cada record. _–El parámetro `dropna = False` nos permite visualizar los valores que podrían ser omitidos en la columna.–_ \n",
    "\n",
    "2.- `DataFrame['columname'].value_counts(dropna=False)` es otra manera de realizar lo anterior.\n",
    "    \n",
    "3.- `DataFrame.describe()` arroja una estadística básica para cada uno de los atributos en el dataframe. Este método es solo se aplica cuando las columnas son de tipo numérico.\n",
    "\n",
    "Al aplicar estos métodos a los atributos `STATE` y `NAME` se observan los siguientes casos:\n",
    "\n",
    "* no todos los registros en el atributo `STATE` son de Pensilvania. Esto es curioso, sobre todo si decimos que el dataset contiene solamente aplicaciones para este estado.\n",
    "\n",
    "* en el atributo `AGE` observamos 4 valores `NaN` que habrá que investigar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PENSILVANIA    14479\n",
       "WYOMING            1\n",
       "Name: STATE, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.STATE.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennsylvanian                 5905\n",
      "Ordovician                    1558\n",
      "Mississippian                 1209\n",
      "Cambrian                       977\n",
      "Devonian                       809\n",
      "Precambrian                    674\n",
      "Permian                        609\n",
      "Triassic                       604\n",
      "Mississippian and Devonian     517\n",
      "Permian and Pennsylvanian      470\n",
      "Silurian                       396\n",
      "Probably lower Paleozoic       353\n",
      "Tertiary                       119\n",
      "Devonian and Silurian          110\n",
      "Jurassic                       110\n",
      "Ordovician and Cambrian         30\n",
      "Cretaceous                      17\n",
      "Quaternary                       8\n",
      "NaN                              4\n",
      "Mowry Shale                      1\n",
      "Name: AGE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(print(df['AGE'].value_counts(dropna=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis explotratorio visual de datos.\n",
    "\n",
    "Hasta ahora hemos estado explorando analíticamente los registros para tratar de encontrar algúna anomalía _(outliers)_ en la información del dataset. Sin embargo podemos apoyarnos de graficos para poder explorar más estos casos.\n",
    "\n",
    "Los gráficos como _histogramas_ y _los boxplots_ son herramientas que nos ayudan en atributos que contienen datos númericos. Por ejemplo para el atributo `Existing Zoning Sqft` utlizamos la función **plot()**, de la librería _matplotlib_, con el parámetro `kind = hist` para poder imprimir un histograma. \n",
    "\n",
    "Antes comensaremos obteniendo rápidamente algunos datos estadísticos para su pre-evaluación y para ello harémos uso de un nuevo _Dataset_. Este nuevo archivo (`ssnmx_01-12_2019.csv`) contiene los registros sísmicos para la republica mexicana, en el periodo _enero 2019 - diciembre 2020_. Además se ha tratado la información para poder ejemplificar algunas cuestiones referentes a este tema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Magnitud</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Referencia de localizacion</th>\n",
       "      <th>Fecha UTC</th>\n",
       "      <th>Hora UTC</th>\n",
       "      <th>Estatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:06:23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.2010</td>\n",
       "      <td>-97.6130</td>\n",
       "      <td>16.1</td>\n",
       "      <td>28 km al NOROESTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:06:23</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:45:58</td>\n",
       "      <td>2.8</td>\n",
       "      <td>32.1832</td>\n",
       "      <td>-115.2490</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18 km al SUROESTE de GPE VICTORIA(KM.43), BC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:45:58</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:54:06</td>\n",
       "      <td>3.2</td>\n",
       "      <td>16.8403</td>\n",
       "      <td>-97.6925</td>\n",
       "      <td>9.9</td>\n",
       "      <td>47 km al SUR de H TLAXIACO, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:54:06</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:36</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.1272</td>\n",
       "      <td>-97.4227</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13 km al NORTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:36</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:40</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16.4152</td>\n",
       "      <td>-98.1633</td>\n",
       "      <td>23.4</td>\n",
       "      <td>14 km al NOROESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:40</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>21:30:13</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.3800</td>\n",
       "      <td>-94.9500</td>\n",
       "      <td>15</td>\n",
       "      <td>10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>03:30:13</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26422</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:26:12</td>\n",
       "      <td>3.6</td>\n",
       "      <td>15.3800</td>\n",
       "      <td>-94.6900</td>\n",
       "      <td>16</td>\n",
       "      <td>104 km al SURESTE de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:26:12</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26423</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:44:48</td>\n",
       "      <td>3.9</td>\n",
       "      <td>15.4700</td>\n",
       "      <td>-95.0800</td>\n",
       "      <td>22</td>\n",
       "      <td>79 km al SUR de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:44:48</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26424</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:47:43</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.3200</td>\n",
       "      <td>-98.2300</td>\n",
       "      <td>12</td>\n",
       "      <td>20 km al OESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:47:43</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26425</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:22:17</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.1200</td>\n",
       "      <td>-92.7200</td>\n",
       "      <td>106</td>\n",
       "      <td>27 km al OESTE de HUIXTLA, CHIS</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>05:22:17</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26426 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha      Hora  Magnitud  Latitud  Longitud Profundidad  \\\n",
       "0      2019-01-01  00:06:23       3.5  16.2010  -97.6130        16.1   \n",
       "1      2019-01-01  00:45:58       2.8  32.1832 -115.2490        20.1   \n",
       "2      2019-01-01  00:54:06       3.2  16.8403  -97.6925         9.9   \n",
       "3      2019-01-01  01:16:36       3.3  16.1272  -97.4227        16.4   \n",
       "4      2019-01-01  01:16:40       3.1  16.4152  -98.1633        23.4   \n",
       "...           ...       ...       ...      ...       ...         ...   \n",
       "26421  2019-12-31  21:30:13       3.6  16.3800  -94.9500          15   \n",
       "26422  2019-12-31  22:26:12       3.6  15.3800  -94.6900          16   \n",
       "26423  2019-12-31  22:44:48       3.9  15.4700  -95.0800          22   \n",
       "26424  2019-12-31  22:47:43       3.3  16.3200  -98.2300          12   \n",
       "26425  2019-12-31  23:22:17       3.8  15.1200  -92.7200         106   \n",
       "\n",
       "                          Referencia de localizacion   Fecha UTC  Hora UTC  \\\n",
       "0               28 km al NOROESTE de RIO GRANDE, OAX  2019-01-01  06:06:23   \n",
       "1       18 km al SUROESTE de GPE VICTORIA(KM.43), BC  2019-01-01  06:45:58   \n",
       "2                    47 km al SUR de H TLAXIACO, OAX  2019-01-01  06:54:06   \n",
       "3                  13 km al NORTE de RIO GRANDE, OAX  2019-01-01  07:16:36   \n",
       "4        14 km al NOROESTE de PINOTEPA NACIONAL, OAX  2019-01-01  07:16:40   \n",
       "...                                              ...         ...       ...   \n",
       "26421  10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX  2020-01-01  03:30:13   \n",
       "26422          104 km al SURESTE de SALINA CRUZ, OAX  2020-01-01  04:26:12   \n",
       "26423               79 km al SUR de SALINA CRUZ, OAX  2020-01-01  04:44:48   \n",
       "26424       20 km al OESTE de PINOTEPA NACIONAL, OAX  2020-01-01  04:47:43   \n",
       "26425                27 km al OESTE de HUIXTLA, CHIS  2020-01-01  05:22:17   \n",
       "\n",
       "          Estatus  \n",
       "0        revisado  \n",
       "1        revisado  \n",
       "2        revisado  \n",
       "3        revisado  \n",
       "4        revisado  \n",
       "...           ...  \n",
       "26421  verificado  \n",
       "26422  verificado  \n",
       "26423  verificado  \n",
       "26424  verificado  \n",
       "26425  verificado  \n",
       "\n",
       "[26426 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssn=pd.read_csv('ssnmx_01-12_2019.csv')\n",
    "df_ssn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inmediatamente podemos hacer un barrido exploratorio con la función `info()` como ya lo vimos en ejemplos anteriores. Podrémos observar que nuestro _Dataset_ contiene `26425` registros (eventos). Sin embargo a simple vista no podríamos identificar datos que nos puedan ensuciar la información. Estos casos pueden ser; _outliers_, _incompatibilidad con el formato de sus atributos_, _valores_ `NaN` o `Null`, _entre otros_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26426 entries, 0 to 26425\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Fecha                       26426 non-null  object \n",
      " 1   Hora                        26426 non-null  object \n",
      " 2   Magnitud                    26426 non-null  float64\n",
      " 3   Latitud                     26426 non-null  float64\n",
      " 4   Longitud                    26426 non-null  float64\n",
      " 5   Profundidad                 26426 non-null  object \n",
      " 6   Referencia de localizacion  26426 non-null  object \n",
      " 7   Fecha UTC                   26426 non-null  object \n",
      " 8   Hora UTC                    26426 non-null  object \n",
      " 9   Estatus                     26426 non-null  object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ssn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin tener mucho conocimiento o experiencia en el _análisis exploratorio de datos_ podemos observar de primera cuenta que el atributo `Profundidad` está clasificado como `object` (_cadena_), a pesar de que los valores reportados en esta columna deberían ser números. _Python_ por defecto clasifica como `object` a cualquier registro que desde su archivo fuente (para este caso `ssnmx_01-12_2019.csv`) contenga caractéres o cadenas (_texto_) en sus atributos.\n",
    "\n",
    "Para tratar de solucionar esta observación podemos indicarle a _Pandas_ que abra nuestro archivo cambiando el formato del atributo `Profundidad` por `float` (decimal). El parámetro que debemos pasarle a pandas es `dtype={'atributo':type}`. Con esto deberíamos poder visualizar nuestro _DataFrame_ correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'menos de 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array from dtype('O') to dtype('float64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-046504476a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ssn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ssnmx_01-12_2019.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Profundidad'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_ssn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/postgres/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/postgres/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/postgres/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/postgres/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'menos de 1'"
     ]
    }
   ],
   "source": [
    "df_ssn=pd.read_csv('ssnmx_01-12_2019.csv', dtype={'Profundidad':float})\n",
    "df_ssn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no tener exito podemos pensar que no es cuestión del formato en nuestro atributo. Seguramente de debe a algo más. Muchas veces hay registros `NaN`,`Null`, registros con caractéres como `*`,`$`,`#` antepuestos, y como ya vimos en el ejemplo anterior no son posibles transformarlos.\n",
    "\n",
    "Si somos observadores en la imprsión de nuestro mensaje de error _Pandas_ nos arroja este mensaje:\n",
    "```pyhton\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.read()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._read_rows()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_column_data()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()\n",
    "\n",
    "ValueError: could not convert string to float: 'menos de 1'\n",
    "```\n",
    "Lo que intenta decirnos este mensaje es que: _–existen registros que no pueden ser convertidos en números, tal es el caso de registros como `menos de 1`–_. Podemos hacer caso y buscar cuales son los registros que cumplen esta condición en. Para ello hay que hacer un filtrado en el atributo `Profundidad`, donde sus registros cumplan con la condición de ser cadenas de texto con el valor igual a `menos de 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Magnitud</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Referencia de localizacion</th>\n",
       "      <th>Fecha UTC</th>\n",
       "      <th>Hora UTC</th>\n",
       "      <th>Estatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14551</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>04:47:41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.4077</td>\n",
       "      <td>-99.1950</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>menos de 1 km al NOROESTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>09:47:41</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14561</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>07:38:28</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.4049</td>\n",
       "      <td>-99.1959</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>1 km al SUROESTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>12:38:28</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14566</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>10:08:04</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.4049</td>\n",
       "      <td>-99.1939</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>menos de 1 km al SUROESTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>15:08:04</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>01:35:36</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.4075</td>\n",
       "      <td>-99.1952</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>menos de 1 km al OESTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>06:35:36</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>11:39:20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.3920</td>\n",
       "      <td>-99.2173</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>2 km al SUROESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>16:39:20</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14859</th>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>23:10:52</td>\n",
       "      <td>2.6</td>\n",
       "      <td>19.4028</td>\n",
       "      <td>-99.2102</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>1 km al NOROESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>04:10:52</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14860</th>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>23:18:46</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.4019</td>\n",
       "      <td>-99.2138</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>1 km al OESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>04:18:46</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>00:41:36</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.3983</td>\n",
       "      <td>-99.2173</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>2 km al OESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>05:41:36</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14871</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>00:45:53</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.4010</td>\n",
       "      <td>-99.2130</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>1 km al OESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>05:45:53</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14874</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>01:04:24</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.3980</td>\n",
       "      <td>-99.2158</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>2 km al OESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>06:04:24</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14924</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>14:28:05</td>\n",
       "      <td>1.9</td>\n",
       "      <td>19.4060</td>\n",
       "      <td>-99.2160</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>2 km al NOROESTE de V ALVARO OBREGON, CDMX</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>19:28:05</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>15:43:50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>19.4260</td>\n",
       "      <td>-99.1918</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>2 km al NORTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>20:43:50</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15002</th>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>16:32:53</td>\n",
       "      <td>1.8</td>\n",
       "      <td>19.4118</td>\n",
       "      <td>-99.1993</td>\n",
       "      <td>menos de 1</td>\n",
       "      <td>1 km al NOROESTE de MIGUEL HIDALGO, CDMX</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>21:32:53</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha      Hora  Magnitud  Latitud  Longitud Profundidad  \\\n",
       "14551  2019-07-12  04:47:41       2.0  19.4077  -99.1950  menos de 1   \n",
       "14561  2019-07-12  07:38:28       2.7  19.4049  -99.1959  menos de 1   \n",
       "14566  2019-07-12  10:08:04       2.4  19.4049  -99.1939  menos de 1   \n",
       "14607  2019-07-13  01:35:36       2.4  19.4075  -99.1952  menos de 1   \n",
       "14641  2019-07-13  11:39:20       2.4  19.3920  -99.2173  menos de 1   \n",
       "14859  2019-07-16  23:10:52       2.6  19.4028  -99.2102  menos de 1   \n",
       "14860  2019-07-16  23:18:46       2.4  19.4019  -99.2138  menos de 1   \n",
       "14869  2019-07-17  00:41:36       2.4  19.3983  -99.2173  menos de 1   \n",
       "14871  2019-07-17  00:45:53       2.4  19.4010  -99.2130  menos de 1   \n",
       "14874  2019-07-17  01:04:24       2.4  19.3980  -99.2158  menos de 1   \n",
       "14924  2019-07-17  14:28:05       1.9  19.4060  -99.2160  menos de 1   \n",
       "14999  2019-07-18  15:43:50       1.5  19.4260  -99.1918  menos de 1   \n",
       "15002  2019-07-18  16:32:53       1.8  19.4118  -99.1993  menos de 1   \n",
       "\n",
       "                              Referencia de localizacion   Fecha UTC  \\\n",
       "14551  menos de 1 km al NOROESTE de MIGUEL HIDALGO, CDMX  2019-07-12   \n",
       "14561           1 km al SUROESTE de MIGUEL HIDALGO, CDMX  2019-07-12   \n",
       "14566  menos de 1 km al SUROESTE de MIGUEL HIDALGO, CDMX  2019-07-12   \n",
       "14607     menos de 1 km al OESTE de MIGUEL HIDALGO, CDMX  2019-07-13   \n",
       "14641         2 km al SUROESTE de V ALVARO OBREGON, CDMX  2019-07-13   \n",
       "14859         1 km al NOROESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14860            1 km al OESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14869            2 km al OESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14871            1 km al OESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14874            2 km al OESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14924         2 km al NOROESTE de V ALVARO OBREGON, CDMX  2019-07-17   \n",
       "14999              2 km al NORTE de MIGUEL HIDALGO, CDMX  2019-07-18   \n",
       "15002           1 km al NOROESTE de MIGUEL HIDALGO, CDMX  2019-07-18   \n",
       "\n",
       "       Hora UTC   Estatus  \n",
       "14551  09:47:41  revisado  \n",
       "14561  12:38:28  revisado  \n",
       "14566  15:08:04  revisado  \n",
       "14607  06:35:36  revisado  \n",
       "14641  16:39:20  revisado  \n",
       "14859  04:10:52  revisado  \n",
       "14860  04:18:46  revisado  \n",
       "14869  05:41:36  revisado  \n",
       "14871  05:45:53  revisado  \n",
       "14874  06:04:24  revisado  \n",
       "14924  19:28:05  revisado  \n",
       "14999  20:43:50  revisado  \n",
       "15002  21:32:53  revisado  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string=df_ssn[df_ssn['Profundidad']=='menos de 1']\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que efectivamente hay una cantidad pequeña de registros que cumplen esta condición. Aquí es donde nuestro sentido sobre el análisis que deseamos efectuar decidirá si eliminar estos datos o tratar de buscar una solución para no perderlos. \n",
    "\n",
    "Pero antes, nuestro objetivo era transformar el tipo de dato de estos valores de cadena a numérico independientemente si cumplian con la condición o no. Si volvemos a realizar un filtro al _DataFrame_\n",
    "`df_ssn` podemos seleccionar aquellos valores que cumplan con la condición opuesta, o sea, que se seleccionen aquellos registros, de en el atributo `Profundidad`, que no cumplan con la condición de ser iguales a `menos de 1`. Este nuevo _DataFrame_ lo llamarémos `df_ssn_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Magnitud</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Referencia de localizacion</th>\n",
       "      <th>Fecha UTC</th>\n",
       "      <th>Hora UTC</th>\n",
       "      <th>Estatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:06:23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.2010</td>\n",
       "      <td>-97.6130</td>\n",
       "      <td>16.1</td>\n",
       "      <td>28 km al NOROESTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:06:23</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:45:58</td>\n",
       "      <td>2.8</td>\n",
       "      <td>32.1832</td>\n",
       "      <td>-115.2490</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18 km al SUROESTE de GPE VICTORIA(KM.43), BC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:45:58</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:54:06</td>\n",
       "      <td>3.2</td>\n",
       "      <td>16.8403</td>\n",
       "      <td>-97.6925</td>\n",
       "      <td>9.9</td>\n",
       "      <td>47 km al SUR de H TLAXIACO, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:54:06</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:36</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.1272</td>\n",
       "      <td>-97.4227</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13 km al NORTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:36</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:40</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16.4152</td>\n",
       "      <td>-98.1633</td>\n",
       "      <td>23.4</td>\n",
       "      <td>14 km al NOROESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:40</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>21:30:13</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.3800</td>\n",
       "      <td>-94.9500</td>\n",
       "      <td>15</td>\n",
       "      <td>10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>03:30:13</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26422</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:26:12</td>\n",
       "      <td>3.6</td>\n",
       "      <td>15.3800</td>\n",
       "      <td>-94.6900</td>\n",
       "      <td>16</td>\n",
       "      <td>104 km al SURESTE de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:26:12</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26423</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:44:48</td>\n",
       "      <td>3.9</td>\n",
       "      <td>15.4700</td>\n",
       "      <td>-95.0800</td>\n",
       "      <td>22</td>\n",
       "      <td>79 km al SUR de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:44:48</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26424</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:47:43</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.3200</td>\n",
       "      <td>-98.2300</td>\n",
       "      <td>12</td>\n",
       "      <td>20 km al OESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:47:43</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26425</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:22:17</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.1200</td>\n",
       "      <td>-92.7200</td>\n",
       "      <td>106</td>\n",
       "      <td>27 km al OESTE de HUIXTLA, CHIS</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>05:22:17</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26413 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha      Hora  Magnitud  Latitud  Longitud Profundidad  \\\n",
       "0      2019-01-01  00:06:23       3.5  16.2010  -97.6130        16.1   \n",
       "1      2019-01-01  00:45:58       2.8  32.1832 -115.2490        20.1   \n",
       "2      2019-01-01  00:54:06       3.2  16.8403  -97.6925         9.9   \n",
       "3      2019-01-01  01:16:36       3.3  16.1272  -97.4227        16.4   \n",
       "4      2019-01-01  01:16:40       3.1  16.4152  -98.1633        23.4   \n",
       "...           ...       ...       ...      ...       ...         ...   \n",
       "26421  2019-12-31  21:30:13       3.6  16.3800  -94.9500          15   \n",
       "26422  2019-12-31  22:26:12       3.6  15.3800  -94.6900          16   \n",
       "26423  2019-12-31  22:44:48       3.9  15.4700  -95.0800          22   \n",
       "26424  2019-12-31  22:47:43       3.3  16.3200  -98.2300          12   \n",
       "26425  2019-12-31  23:22:17       3.8  15.1200  -92.7200         106   \n",
       "\n",
       "                          Referencia de localizacion   Fecha UTC  Hora UTC  \\\n",
       "0               28 km al NOROESTE de RIO GRANDE, OAX  2019-01-01  06:06:23   \n",
       "1       18 km al SUROESTE de GPE VICTORIA(KM.43), BC  2019-01-01  06:45:58   \n",
       "2                    47 km al SUR de H TLAXIACO, OAX  2019-01-01  06:54:06   \n",
       "3                  13 km al NORTE de RIO GRANDE, OAX  2019-01-01  07:16:36   \n",
       "4        14 km al NOROESTE de PINOTEPA NACIONAL, OAX  2019-01-01  07:16:40   \n",
       "...                                              ...         ...       ...   \n",
       "26421  10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX  2020-01-01  03:30:13   \n",
       "26422          104 km al SURESTE de SALINA CRUZ, OAX  2020-01-01  04:26:12   \n",
       "26423               79 km al SUR de SALINA CRUZ, OAX  2020-01-01  04:44:48   \n",
       "26424       20 km al OESTE de PINOTEPA NACIONAL, OAX  2020-01-01  04:47:43   \n",
       "26425                27 km al OESTE de HUIXTLA, CHIS  2020-01-01  05:22:17   \n",
       "\n",
       "          Estatus  \n",
       "0        revisado  \n",
       "1        revisado  \n",
       "2        revisado  \n",
       "3        revisado  \n",
       "4        revisado  \n",
       "...           ...  \n",
       "26421  verificado  \n",
       "26422  verificado  \n",
       "26423  verificado  \n",
       "26424  verificado  \n",
       "26425  verificado  \n",
       "\n",
       "[26413 rows x 10 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssn_clean=df_ssn.loc[df_ssn['Profundidad']!='menos de 1']\n",
    "df_ssn_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseamos, hasta aquí, podemos trabajar con el resto de los datos sin esta condición. La fucnión `astype()` nos otorga la posibilidad de agregar un diccionario, como parámetro, para indicar que atributo y a que nuevo formato deseamos transformarlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Magnitud</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Referencia de localizacion</th>\n",
       "      <th>Fecha UTC</th>\n",
       "      <th>Hora UTC</th>\n",
       "      <th>Estatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:06:23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.2010</td>\n",
       "      <td>-97.6130</td>\n",
       "      <td>16.1</td>\n",
       "      <td>28 km al NOROESTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:06:23</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:45:58</td>\n",
       "      <td>2.8</td>\n",
       "      <td>32.1832</td>\n",
       "      <td>-115.2490</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18 km al SUROESTE de GPE VICTORIA(KM.43), BC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:45:58</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:54:06</td>\n",
       "      <td>3.2</td>\n",
       "      <td>16.8403</td>\n",
       "      <td>-97.6925</td>\n",
       "      <td>9.9</td>\n",
       "      <td>47 km al SUR de H TLAXIACO, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>06:54:06</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:36</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.1272</td>\n",
       "      <td>-97.4227</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13 km al NORTE de RIO GRANDE, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:36</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:16:40</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16.4152</td>\n",
       "      <td>-98.1633</td>\n",
       "      <td>23.4</td>\n",
       "      <td>14 km al NOROESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>07:16:40</td>\n",
       "      <td>revisado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>21:30:13</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.3800</td>\n",
       "      <td>-94.9500</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>03:30:13</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26422</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:26:12</td>\n",
       "      <td>3.6</td>\n",
       "      <td>15.3800</td>\n",
       "      <td>-94.6900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>104 km al SURESTE de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:26:12</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26423</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:44:48</td>\n",
       "      <td>3.9</td>\n",
       "      <td>15.4700</td>\n",
       "      <td>-95.0800</td>\n",
       "      <td>22.0</td>\n",
       "      <td>79 km al SUR de SALINA CRUZ, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:44:48</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26424</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22:47:43</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.3200</td>\n",
       "      <td>-98.2300</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20 km al OESTE de PINOTEPA NACIONAL, OAX</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>04:47:43</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26425</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:22:17</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.1200</td>\n",
       "      <td>-92.7200</td>\n",
       "      <td>106.0</td>\n",
       "      <td>27 km al OESTE de HUIXTLA, CHIS</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>05:22:17</td>\n",
       "      <td>verificado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26413 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha      Hora  Magnitud  Latitud  Longitud  Profundidad  \\\n",
       "0      2019-01-01  00:06:23       3.5  16.2010  -97.6130         16.1   \n",
       "1      2019-01-01  00:45:58       2.8  32.1832 -115.2490         20.1   \n",
       "2      2019-01-01  00:54:06       3.2  16.8403  -97.6925          9.9   \n",
       "3      2019-01-01  01:16:36       3.3  16.1272  -97.4227         16.4   \n",
       "4      2019-01-01  01:16:40       3.1  16.4152  -98.1633         23.4   \n",
       "...           ...       ...       ...      ...       ...          ...   \n",
       "26421  2019-12-31  21:30:13       3.6  16.3800  -94.9500         15.0   \n",
       "26422  2019-12-31  22:26:12       3.6  15.3800  -94.6900         16.0   \n",
       "26423  2019-12-31  22:44:48       3.9  15.4700  -95.0800         22.0   \n",
       "26424  2019-12-31  22:47:43       3.3  16.3200  -98.2300         12.0   \n",
       "26425  2019-12-31  23:22:17       3.8  15.1200  -92.7200        106.0   \n",
       "\n",
       "                          Referencia de localizacion   Fecha UTC  Hora UTC  \\\n",
       "0               28 km al NOROESTE de RIO GRANDE, OAX  2019-01-01  06:06:23   \n",
       "1       18 km al SUROESTE de GPE VICTORIA(KM.43), BC  2019-01-01  06:45:58   \n",
       "2                    47 km al SUR de H TLAXIACO, OAX  2019-01-01  06:54:06   \n",
       "3                  13 km al NORTE de RIO GRANDE, OAX  2019-01-01  07:16:36   \n",
       "4        14 km al NOROESTE de PINOTEPA NACIONAL, OAX  2019-01-01  07:16:40   \n",
       "...                                              ...         ...       ...   \n",
       "26421  10 km al SURESTE de JUCHITAN DE ZARAGOZA, OAX  2020-01-01  03:30:13   \n",
       "26422          104 km al SURESTE de SALINA CRUZ, OAX  2020-01-01  04:26:12   \n",
       "26423               79 km al SUR de SALINA CRUZ, OAX  2020-01-01  04:44:48   \n",
       "26424       20 km al OESTE de PINOTEPA NACIONAL, OAX  2020-01-01  04:47:43   \n",
       "26425                27 km al OESTE de HUIXTLA, CHIS  2020-01-01  05:22:17   \n",
       "\n",
       "          Estatus  \n",
       "0        revisado  \n",
       "1        revisado  \n",
       "2        revisado  \n",
       "3        revisado  \n",
       "4        revisado  \n",
       "...           ...  \n",
       "26421  verificado  \n",
       "26422  verificado  \n",
       "26423  verificado  \n",
       "26424  verificado  \n",
       "26425  verificado  \n",
       "\n",
       "[26413 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssn_clean = df_ssn_clean.astype({\"Profundidad\": float})\n",
    "df_ssn_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26413 entries, 0 to 26425\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Fecha                       26413 non-null  object \n",
      " 1   Hora                        26413 non-null  object \n",
      " 2   Magnitud                    26413 non-null  float64\n",
      " 3   Latitud                     26413 non-null  float64\n",
      " 4   Longitud                    26413 non-null  float64\n",
      " 5   Profundidad                 26413 non-null  float64\n",
      " 6   Referencia de localizacion  26413 non-null  object \n",
      " 7   Fecha UTC                   26413 non-null  object \n",
      " 8   Hora UTC                    26413 non-null  object \n",
      " 9   Estatus                     26413 non-null  object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ssn_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver el atributo profundidad cambio de ser `object` a `float`, como tenía que ser desde un principio. Ahora podemos inspeccionar un poco más nuestro _DataFrame_. Podemos utilizar la función `describe()` y obtener más información sobre el atributo `Profundidad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26413.000000\n",
       "mean        35.090145\n",
       "std        370.733735\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         16.200000\n",
       "75%         42.100000\n",
       "max      60000.000000\n",
       "Name: Profundidad, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssn_clean.Profundidad.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De primera cuenta podemos observar que hay una gran distancia entre el valor máximo y el valor mínimo en nuestros registros **min  1.0 km** y **max  60,000 km**. En primera; sería muy dificil tener confianza en un dato que provenga desde esa profundidad, sobre todo por que no existiría si tomamos en cuenta que el radio de la tierra es de **~6,300 kms** (aprox). EN segunda; estamos hablando de una profundidad mayor a la del núcleo interno, donde ya no existen placas tectónicas, todo se fusionó y se reciclo kilómetros arriba. Entonces es recomendable visualizar como se distribuyen las frecuencias de la `Prifundidad` de nuestros registros en un histograma. \n",
    "\n",
    "Para esta ocación ajustaremos logaritmicamente la escala del eje `y` para una visualización más comoda. Utilizamos entonces los parámetros `logy=True` en la función `plot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_ssn_clean['Profundidad'].plot(kind='hist', logy=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver; el **histograma**  nos ayuda a visualizar mejor la distribución de frecuencias de nuestros datos, un poco más que la forma analítica. Pero ninguna técnica es mejor que otra ya que antes de utilizar métodos gráficos necesitamos la descripción de nuestro _Dataset_ para esperar entender el resutado de este. Podemos hacernos la siguiente pregunta _–¿hacia que lado se encuentran más cargados nuestros registros?.–_\n",
    "\n",
    "En el gráfico podemos identificar (según nuestro rapido análisis analítico) que; el **25%, 50% y 75%** de los registros se encuentran hacia la izquierda, con valores menores a los `10,000 km` de `Profundidad`. Y sin embargo, a los lados del registro con mayor valor (última barra azul) no hay casi datos. Por lo cual diremos que este valor es considerado como anómalo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los _histográmas_ nos ayudan para visualizar solo una varaiable. Para visualizar multiples variables los _boxplots_ son una gran ayuda, especialmente cuando las varaiables son categóricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postgres/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job #</th>\n",
       "      <th>Doc #</th>\n",
       "      <th>Borough</th>\n",
       "      <th>House #</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Bin #</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Owner's Last Name</th>\n",
       "      <th>Owner's Business Name</th>\n",
       "      <th>Owner's House Number</th>\n",
       "      <th>Owner'sHouse Street Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Owner'sPhone #</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>DOBRunDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121577873</td>\n",
       "      <td>2</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>386</td>\n",
       "      <td>PARK AVENUE SOUTH</td>\n",
       "      <td>857</td>\n",
       "      <td>38</td>\n",
       "      <td>1016890</td>\n",
       "      <td>A2</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>MIGLIORE</td>\n",
       "      <td>MACKLOWE MANAGEMENT</td>\n",
       "      <td>126</td>\n",
       "      <td>EAST 56TH STREET</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10222</td>\n",
       "      <td>2125545837</td>\n",
       "      <td>GENERAL MECHANICAL &amp; PLUMBING MODIFICATIONS AS...</td>\n",
       "      <td>04/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520129502</td>\n",
       "      <td>1</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>107</td>\n",
       "      <td>KNOX PLACE</td>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>5161350</td>\n",
       "      <td>A3</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>BLUMENBERG</td>\n",
       "      <td>NA</td>\n",
       "      <td>107</td>\n",
       "      <td>KNOX PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "      <td>10314</td>\n",
       "      <td>3477398892</td>\n",
       "      <td>BUILDERS PAVEMENT PLAN 143 LF.                ...</td>\n",
       "      <td>04/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121601560</td>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>63</td>\n",
       "      <td>WEST 131 STREET</td>\n",
       "      <td>1729</td>\n",
       "      <td>9</td>\n",
       "      <td>1053831</td>\n",
       "      <td>A2</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>MARKOWITZ</td>\n",
       "      <td>635 RIVERSIDE DRIVE NY LLC</td>\n",
       "      <td>619</td>\n",
       "      <td>WEST 54TH STREET</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10016</td>\n",
       "      <td>2127652555</td>\n",
       "      <td>GENERAL CONSTRUCTION TO INCLUDE NEW PARTITIONS...</td>\n",
       "      <td>04/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121601203</td>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>48</td>\n",
       "      <td>WEST 25TH STREET</td>\n",
       "      <td>826</td>\n",
       "      <td>69</td>\n",
       "      <td>1015610</td>\n",
       "      <td>A2</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>CASALE</td>\n",
       "      <td>48 W 25 ST LLC C/O BERNSTEIN</td>\n",
       "      <td>150</td>\n",
       "      <td>WEST 30TH STREET</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10001</td>\n",
       "      <td>2125941414</td>\n",
       "      <td>STRUCTURAL CHANGES ON THE 5TH FLOOR (MOONDOG E...</td>\n",
       "      <td>04/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121601338</td>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>45</td>\n",
       "      <td>WEST 29 STREET</td>\n",
       "      <td>831</td>\n",
       "      <td>7</td>\n",
       "      <td>1015754</td>\n",
       "      <td>A3</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>LEE</td>\n",
       "      <td>HYUNG-HYANG REALTY CORP</td>\n",
       "      <td>614</td>\n",
       "      <td>8 AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10001</td>\n",
       "      <td>2019881222</td>\n",
       "      <td>FILING HEREWITH FACADE REPAIR PLANS. WORK SCOP...</td>\n",
       "      <td>04/26/2013 12:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Job #  Doc #        Borough       House #  \\\n",
       "0  121577873      2      MANHATTAN  386            \n",
       "1  520129502      1  STATEN ISLAND  107            \n",
       "2  121601560      1      MANHATTAN  63             \n",
       "3  121601203      1      MANHATTAN  48             \n",
       "4  121601338      1      MANHATTAN  45             \n",
       "\n",
       "                        Street Name  Block  Lot    Bin # Job Type Job Status  \\\n",
       "0  PARK AVENUE SOUTH                   857   38  1016890       A2          D   \n",
       "1  KNOX PLACE                          342    1  5161350       A3          A   \n",
       "2  WEST 131 STREET                    1729    9  1053831       A2          Q   \n",
       "3  WEST 25TH STREET                    826   69  1015610       A2          D   \n",
       "4  WEST 29 STREET                      831    7  1015754       A3          D   \n",
       "\n",
       "   ...               Owner's Last Name             Owner's Business Name  \\\n",
       "0  ...  MIGLIORE                        MACKLOWE MANAGEMENT                \n",
       "1  ...  BLUMENBERG                      NA                                 \n",
       "2  ...  MARKOWITZ                       635 RIVERSIDE DRIVE NY LLC         \n",
       "3  ...  CASALE                          48 W 25 ST LLC C/O BERNSTEIN       \n",
       "4  ...  LEE                             HYUNG-HYANG REALTY CORP            \n",
       "\n",
       "  Owner's House Number          Owner'sHouse Street Name            City   \\\n",
       "0         126           EAST 56TH STREET                  NEW YORK          \n",
       "1         107           KNOX PLACE                        STATEN ISLAND     \n",
       "2         619           WEST 54TH STREET                  NEW YORK          \n",
       "3         150           WEST 30TH STREET                  NEW YORK          \n",
       "4         614           8 AVENUE                          NEW YORK          \n",
       "\n",
       "  State    Zip Owner'sPhone #  \\\n",
       "0    NY  10222     2125545837   \n",
       "1    NY  10314     3477398892   \n",
       "2    NY  10016     2127652555   \n",
       "3    NY  10001     2125941414   \n",
       "4    NY  10001     2019881222   \n",
       "\n",
       "                                     Job Description              DOBRunDate  \n",
       "0  GENERAL MECHANICAL & PLUMBING MODIFICATIONS AS...  04/26/2013 12:00:00 AM  \n",
       "1  BUILDERS PAVEMENT PLAN 143 LF.                ...  04/26/2013 12:00:00 AM  \n",
       "2  GENERAL CONSTRUCTION TO INCLUDE NEW PARTITIONS...  04/26/2013 12:00:00 AM  \n",
       "3  STRUCTURAL CHANGES ON THE 5TH FLOOR (MOONDOG E...  04/26/2013 12:00:00 AM  \n",
       "4  FILING HEREWITH FACADE REPAIR PLANS. WORK SCOP...  04/26/2013 12:00:00 AM  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('dob_job_application_subset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo usaremos _boxplots_ para comparar `initial cost` a través de diferentes valores de `Borough` con ayuda del método `.boxplot()` de la librería de **pandas**: `df.boxplot(column='name_column', by='parameter', rot=90)`. Esta gráfica será el resultado de para una nueva variable llamada **df_boxplot** que alojará a los atributos `Initial Cost` y `Borough`.\n",
    "\n",
    "Ates de graficar es necesario realizar unos cambios en el formato del atributo `Initial Cost`:\n",
    "\n",
    "* Eliminar `$` del la columna `Initial Cost` : `ini_cost = df['Initial Cost']str.replace('$', '')`.\n",
    "\n",
    "* Convertir `Initial Cost` a formato `float`: `astype(float)`\n",
    "\n",
    "* Creación de la nueva variable **df_boxplot**: `df_boxplt= pd.concat([df['Borough'],ini_cost], axis=1)`.\n",
    "\n",
    "Una vez realizados estos cambios podemos construir la gráfica de la siguiente manera: `df_boxplt.boxplot(column='Initial Cost', by='Borough', rot=90)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Initial Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>19500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Borough  Initial Cost\n",
       "0      MANHATTAN       75000.0\n",
       "1  STATEN ISLAND           0.0\n",
       "2      MANHATTAN       30000.0\n",
       "3      MANHATTAN        1500.0\n",
       "4      MANHATTAN       19500.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_cost = df['Initial Cost'].str.replace('$', '').astype(float)\n",
    "df_boxplt= pd.concat([df['Borough'],ini_cost], axis=1)\n",
    "df_boxplt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_boxplt.boxplot(column='Initial Cost', by='Borough', rot=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay dos _outliers_ en _\"Manhatan\"_ esto se debe a que es uno de los lugares más caros y por lo tanto es normal. Este es un claro ejemplo cuando hay que tener en cuenta e identificar muy bien &mdash; _¿ qué consideramos ouliers y qué no ?_ &mdash;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Boxplot_ es una excelente opción cuando se tiene una columna, con valor numérico, y deseamos compararla con varias atributos. Pero cuando necesitamos visualizar 2 columnas numéricas _Scatter PLots_ es la mejor opción.  \n",
    "\n",
    "Imprimamos la gráfica con `Initial_cost`, en el eje de las `x` y `total_est_fee` en el eje de las `y`. Utilizaremos el método `.plot` con el parámetro `Kind='scatter'` y noteremos que hay dos _outliers_ que se alcanzan a visualizar. Para ello necesitamos realizar un proceso parecido con **df_boxplt**, donde `Total Est. Fee` del dataframe **df** necesita eliminar `$` y convertirse en una variable `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial Cost</th>\n",
       "      <th>Total Est. Fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>522.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19500.0</td>\n",
       "      <td>389.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Initial Cost  Total Est. Fee\n",
       "0       75000.0           986.0\n",
       "1           0.0          1144.0\n",
       "2       30000.0           522.5\n",
       "3        1500.0           225.0\n",
       "4       19500.0           389.5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_est_fee=df['Total Est. Fee'].str.replace('$', '').astype(float)\n",
    "df_scatter=pd.concat([ini_cost,total_est_fee], axis=1)\n",
    "df_scatter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces escribimos la siguiente línea: `df.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)` pararealizar la impresión del gráfico _scatter plot_ sobre los atributos `Initia Cost` y `Total Est.Fee`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scatter.plot(kind='scatter', x='Initial Cost', y='Total Est. Fee', rot=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente los _outlayers_ se ven presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy data\n",
    "\n",
    "Existen do premisas que hacen a un Dataset organizado y consistente:\n",
    "\n",
    "* Cada atributo estará representando a variables diferentes.\n",
    "\n",
    "* Los renglones deberán alojar registros únicos e independientes.\n",
    "\n",
    "* Las dos premisas anteriores forman una Tabla.\n",
    "\n",
    "Un claro ejemolplo de esto es cuando en lugar de tener atributos (columnas) que representea variables, se tienen valores. Esto es algo que es impresindible identificar.\n",
    "\n",
    "Por ejemplo: _en el siguiente DataFrame observamos un caso tipico de inconsitencia, ya que los atributos no representan variables, si no valores de la variable \"tratamiento\"._\n",
    "\n",
    "Otra observación es que: _para el valor \"tratamiento-a\" los registros \"b\" se hacen presentes. Lo cual también indica una inconsitencia para los datos._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tratamiento-a</th>\n",
       "      <th>beneficiario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>Alejandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>Gustavo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>Claudia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>Mónica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tratamiento-a beneficiario\n",
       "0             a    Alejandro\n",
       "1             b      Gustavo\n",
       "2             b      Claudia\n",
       "3             b       Mónica"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tratamiento=['a','b','b','b']\n",
    "paciente=['Alejandro', 'Gustavo', 'Claudia', 'Mónica']\n",
    "error={'tratamiento-a':tratamiento, 'beneficiario':paciente}\n",
    "dict_error=pd.DataFrame(error)\n",
    "dict_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melting\n",
    "\n",
    "En ocaciones es necesario trasformar nuestro Dataset en una tabla que tenga un mejor entendimiento o una mejor vista. Uno de los procesos más comunes es realizar un _Melting_ lo que significa transformar las columnas en renglones.\n",
    "\n",
    "Para el siguiente Dataframe los atributos `Ozone`, `Solar . R`, `Wind` y `Temp` estan representados, cada uno, en una columna. Si por alguna razón necesitamos convertir estos datos en reglones aplicamos el método _melt_. Necesitamos entonces identificar los arámetro `id_vars` y `value_vars`.\n",
    "\n",
    "* `id_vars` representa las columnas que no deseamos transponer.\n",
    "\n",
    "* `value_vars` representa las columnas que deseamos convertir en renglones.\n",
    "\n",
    "El Dataset que vamos a ocupar es en esta ocación es **airquality.csv** y mantengamos en mente que tiene la siguiente estructura (`153,6`) que es igual a `153` registros u observaciones y `6` atributos o variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality=pd.read_csv('airquality.csv')\n",
    "airquality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Day variable  value\n",
       "0      5    1    Ozone   41.0\n",
       "1      5    2    Ozone   36.0\n",
       "2      5    3    Ozone   12.0\n",
       "3      5    4    Ozone   18.0\n",
       "4      5    5    Ozone    NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_metl=pd.melt(airquality, id_vars=['Month','Day'])\n",
    "airquality_metl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos renombrar los atributos (columnas) una vez usado **melting** en el nuevo _Dataframe_. Solo necesitamos los siguientes parámetros:\n",
    "\n",
    "* `var_name = 'new_name'` representará el nuevo nombre para nuestro atributo.\n",
    "\n",
    "* `value_name = 'new_name'` que será el nombre para la nueva columna de los valores transpuestos de nuestro nuevo atributo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>measurement</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Day measurement  reading\n",
       "0      5    1       Ozone     41.0\n",
       "1      5    2       Ozone     36.0\n",
       "2      5    3       Ozone     12.0\n",
       "3      5    4       Ozone     18.0\n",
       "4      5    5       Ozone      NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')\n",
    "airquality_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot\n",
    "\n",
    "Mientras _melting_ convierte atributos en renglones _pivot_ crea un nuevo atributo, con los valores únicos, a partir de un atributo seleccionado.\n",
    "\n",
    "`.pivot_table()` necesita los siguientes parámetros:\n",
    "\n",
    "* `index` será el atributo o atributos que no serán tomados en cuenta en el pivoteo.\n",
    "\n",
    "* `colums` el nombre de la columna o columnas que deseamos utilizar como pivote.\n",
    "\n",
    "* `values` los valores que serán utilizados pra el atributo que utilizamos como pivote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "measurement  Ozone  Solar.R  Temp  Wind\n",
       "Month Day                              \n",
       "5     1       41.0    190.0  67.0   7.4\n",
       "      2       36.0    118.0  72.0   8.0\n",
       "      3       12.0    149.0  74.0  12.6\n",
       "      4       18.0    313.0  62.0  11.5\n",
       "      5        NaN      NaN  56.0  14.3"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_pivot =airquality_melt.pivot_table(index=['Month','Day'], columns='measurement', values='reading')\n",
    "airquality_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder regresar al Dataframe original utilizamos el método `reset_index()`. Sin embargo necesitamos crear un supusesto escenario donde accidentalmente los datos en nuestro dataset **airquality** se duplicaron. Las siguientes líneas crearán renglones duplicados para este ejercicio y podremos observar al final que; para el atributo `reading=41` los datos se duplican.\n",
    "\n",
    "Los datos duplicados estarán alojados en un _Dataframe_ de nombre **airquality_dup**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>measurement</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  Day measurement  reading\n",
       "0         5    1       Ozone     41.0\n",
       "612       5    1       Ozone     41.0\n",
       "1224      5    1       Ozone     41.0\n",
       "1836      5    1       Ozone     41.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_dup=airquality_melt\n",
    "airquality_dup=airquality_dup.append([airquality_dup]*3, ignore_index=True) \n",
    "airquality_dup[airquality_dup['reading']==41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí podemos observar que **airquality_pivot** está bajo la operación `pivot_table()` anteriormente realizada. Su construcción es de tipo (`153,4`). Necesesitamos regresar al punto inicial donde la tabla **airquality**, antes de ser procesada varias ocaciones, tenia una construcción (`153,6`).\n",
    "\n",
    "`reset_index()` necesita los siguientes parámetros:\n",
    "\n",
    "* `index` serán las columnas que deseamos transponer.\n",
    "\n",
    "* `values` los valores que serán utiliazados como registros en nuestros atributos después de realizar el pivoteo al Dataset.\n",
    "\n",
    "* `column` la columna pivote.\n",
    "\n",
    "* `aggfunc` este método acepta la función de agregación **mean** con la cual agrupará a los datos duplicados por. \n",
    "\n",
    "Al final observaremos que **airquality_pivote** tiene de nueva cuenta los mísmo renglones y las mismas columnas como en un principio con el _Dataframe_ **airquality**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>measurement</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "measurement  Month  Day  Ozone  Solar.R  Temp  Wind\n",
       "0                5    1   41.0    190.0  67.0   7.4\n",
       "1                5    2   36.0    118.0  72.0   8.0\n",
       "2                5    3   12.0    149.0  74.0  12.6\n",
       "3                5    4   18.0    313.0  62.0  11.5\n",
       "4                5    5    NaN      NaN  56.0  14.3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "airquality_pivot = airquality_dup.pivot_table(index=['Month','Day'], columns='measurement', values='reading', aggfunc=np.mean)\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "airquality_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_melting_ y _pivot_ son herramientas que necesitamos continuamente cuando es necesario hacer un _reshaping_. Otro problema muy común es cuando en un mismo atributo (columna) tenemos multiple información alojada. \n",
    "\n",
    "#### Separación de caracteres\n",
    "\n",
    "La tabla **tuberculosis** aloja registros de casos reportados para los atributos `country`, `year`, `gender` y grupo de edades `age group`. El ejercicio  para esta ocasión es obtener dos atributos uno para el simple _genero, `m`, y otra para el rango de edad `0-14...`. Esto se logrará separando los caracteres del título del atributo `age group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>m014</th>\n",
       "      <th>m1524</th>\n",
       "      <th>m2534</th>\n",
       "      <th>m3544</th>\n",
       "      <th>m4554</th>\n",
       "      <th>m5564</th>\n",
       "      <th>m65</th>\n",
       "      <th>mu</th>\n",
       "      <th>f014</th>\n",
       "      <th>f1524</th>\n",
       "      <th>f2534</th>\n",
       "      <th>f3544</th>\n",
       "      <th>f4554</th>\n",
       "      <th>f5564</th>\n",
       "      <th>f65</th>\n",
       "      <th>fu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  m014  m1524  m2534  m3544  m4554  m5564   m65  mu  f014  \\\n",
       "0      AD  2000   0.0    0.0    1.0    0.0    0.0    0.0   0.0 NaN   NaN   \n",
       "1      AE  2000   2.0    4.0    4.0    6.0    5.0   12.0  10.0 NaN   3.0   \n",
       "2      AF  2000  52.0  228.0  183.0  149.0  129.0   94.0  80.0 NaN  93.0   \n",
       "3      AG  2000   0.0    0.0    0.0    0.0    0.0    0.0   1.0 NaN   1.0   \n",
       "4      AL  2000   2.0   19.0   21.0   14.0   24.0   19.0  16.0 NaN   3.0   \n",
       "\n",
       "   f1524  f2534  f3544  f4554  f5564   f65  fu  \n",
       "0    NaN    NaN    NaN    NaN    NaN   NaN NaN  \n",
       "1   16.0    1.0    3.0    0.0    0.0   4.0 NaN  \n",
       "2  414.0  565.0  339.0  205.0   99.0  36.0 NaN  \n",
       "3    1.0    1.0    0.0    0.0    0.0   0.0 NaN  \n",
       "4   11.0   10.0    8.0    8.0    5.0  11.0 NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb=pd.read_csv('tuberculosis.csv')\n",
    "tb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder separar este atributo en dos columnas necesitamos realizar un _melting_ pasando como parámetro `id_vars` a `country` y `years` ya que no queremos que estos atributos sufran un cambio. Este proceso será alojado en un nuevo _DataFrame_ llamado **tb_melt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year variable  value\n",
       "0      AD  2000     m014    0.0\n",
       "1      AE  2000     m014    2.0\n",
       "2      AF  2000     m014   52.0\n",
       "3      AG  2000     m014    0.0\n",
       "4      AL  2000     m014    2.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_melt=pd.melt(tb, id_vars=['country','year'])\n",
    "tb_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después es necesario crear los nuevos atributos `gender` y `age_group`. Para ello es necesario apoyarnos de los `slicing` para poder acceder a la posición de los registros en el atributo `variable` del nuevo _Dataframe_ **tb_melt**. Esto lo podemos realizar de la siguiente manera: `DataFrame['new_colum]=DataFrame.variable.str[slicing or string position]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2.0</td>\n",
       "      <td>m</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>52.0</td>\n",
       "      <td>m</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2.0</td>\n",
       "      <td>m</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year variable  value gender age_group\n",
       "0      AD  2000     m014    0.0      m       014\n",
       "1      AE  2000     m014    2.0      m       014\n",
       "2      AF  2000     m014   52.0      m       014\n",
       "3      AG  2000     m014    0.0      m       014\n",
       "4      AL  2000     m014    2.0      m       014"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_melt['gender']=tb_melt.variable.str[0]\n",
    "tb_melt['age_group']=tb_melt.variable.str[1:]\n",
    "tb_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Separación con los métodos split y get.\n",
    "\n",
    "Observemos los atributos del siguiente _DataFrame_ **ebola**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
       "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
       "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
       "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
       "       'Deaths_Spain', 'Deaths_Mali'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola=pd.read_csv('ebola.csv')\n",
    "ebola.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos que los títulos se componen de dos partes _Cases_ o _Deaths_ y la segunda parte por _Country_. Si queremos separar los guiones bajos `_` no podemos realizarlo como en el ejercicio anterior. Es necesario utilizar métodos _built-string_ que divide en varias partes una cadena.\n",
    "\n",
    "Por ejemplo: si al atrubuto `atribute_colum` con registros `Char1_Char2` le aplicamos el meétodo `Cases_Guinea.split('_')`, sobre un nuevo atributo (`atribute_splited`) que anteriormente hayamos creado, tendremos como resultado la división de la cadena ~~`Char1_Char2`~~ según el número de `_` que contengan nuestros registros. Estos serán alojados en una lista (`['Char1','Char2']`) y serán los nuevos registros para el nuevo atributo creado anteriormente (`atribute_splited`). De esta manera apoyados de `.str` y `get()` podremos acceder a los elementos de esta lista y posteriormente separarlos como regitros independientes.\n",
    "\n",
    "Nuestro nuevo ejercicio será reconstruir, en un _Dataframe_ nuevo, el dataset **ebola**. Este _Dataframe_ deberá contener un atributo `type` para los rcaracteres `Cases` o `Death` y un atributo `Country` para el país según sea el caso. Antes que nada necesitamos procesar el Dataframe **ebola** aplicando _melting_. Anteriormente vimos que la sintaxis para ejecutar el método `melt` era la siguiente: `DataFrame['new_colum]=pd.melt(Dataframe, id_vars=['atribute_col1', 'atribute_col2'], var_name='new_atribute_name', value_name='new_atribute_name')`\n",
    "\n",
    "Los parámetros en esta ocasión serán:\n",
    "\n",
    "* `id_vars=['Date','Day']` ya que son los atributos que no veran cambios.\n",
    "\n",
    "* `var_name='type_country'` que es el nuevo atributo donde se volcarán todos los demás atributos.\n",
    "\n",
    "* `value_name='counts'` alojará el registro de los atributos volcados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>type_country</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day  type_country  counts\n",
       "0    1/5/2015  289  Cases_Guinea  2776.0\n",
       "1    1/4/2015  288  Cases_Guinea  2775.0\n",
       "2    1/3/2015  287  Cases_Guinea  2769.0\n",
       "3    1/2/2015  286  Cases_Guinea     NaN\n",
       "4  12/31/2014  284  Cases_Guinea  2730.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola_melt=pd.melt(ebola, id_vars=['Date','Day'], var_name='type_country', value_name='counts')\n",
    "ebola_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es dividir con el metodo `.split()`, el nuevo atributo `type_country`, en dos. Pero antes es necesario crear otro nuevo atributo más (`str_split`) que alojará a la lista con las cadenas divididas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>type_country</th>\n",
       "      <th>counts</th>\n",
       "      <th>str_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day  type_country  counts        str_split\n",
       "0    1/5/2015  289  Cases_Guinea  2776.0  [Cases, Guinea]\n",
       "1    1/4/2015  288  Cases_Guinea  2775.0  [Cases, Guinea]\n",
       "2    1/3/2015  287  Cases_Guinea  2769.0  [Cases, Guinea]\n",
       "3    1/2/2015  286  Cases_Guinea     NaN  [Cases, Guinea]\n",
       "4  12/31/2014  284  Cases_Guinea  2730.0  [Cases, Guinea]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')\n",
    "ebola_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es turno de crear los atributos finales `type` y `country`. Es aquí donde utilizarémos a los métodos `.str` y `.get()` para extraer los elementos de la lista y asignarlos a los atributos correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>type_country</th>\n",
       "      <th>counts</th>\n",
       "      <th>str_split</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>[Cases, Guinea]</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day  type_country  counts        str_split   type country\n",
       "0    1/5/2015  289  Cases_Guinea  2776.0  [Cases, Guinea]  Cases  Guinea\n",
       "1    1/4/2015  288  Cases_Guinea  2775.0  [Cases, Guinea]  Cases  Guinea\n",
       "2    1/3/2015  287  Cases_Guinea  2769.0  [Cases, Guinea]  Cases  Guinea\n",
       "3    1/2/2015  286  Cases_Guinea     NaN  [Cases, Guinea]  Cases  Guinea\n",
       "4  12/31/2014  284  Cases_Guinea  2730.0  [Cases, Guinea]  Cases  Guinea"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola_melt['type'] = ebola_melt.str_split.str.get(0)\n",
    "ebola_melt['country'] = ebola_melt.str_split.str.get(1)\n",
    "ebola_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de datos\n",
    "\n",
    "#### Combinación de datos.\n",
    "\n",
    "El Dataset **nyc_uber_2014.csv** contiene datos de **Nueva York** de **UBER**. Este ejercicio constará en reunir _concatenar_ 3 archivos **uber_4**, **uber_5** y **uber_6** en uno solo, parecido al de **nyc_uber_2014.csv**\n",
    "\n",
    "Sin embargo antes de empezar es necesario la creación de los archivos que contengan los datos para cada mes:\n",
    "\n",
    "* El primer paso es poder manipular mejor el _Dataset_  y para eso es necesario cambiar de nombre al atributo `Data/Time` por `dt_time`.\n",
    "\n",
    "* Hay que identificar cada mes en el _Dataset_ por mese, podemos hacer esto usando `.split` y `get()` sobre el nuevo atributo `dt_time`.\n",
    "\n",
    "* Creamos 3 datasets de nombre **uber_n**, donde **n** es el número correspondiente del mes.\n",
    "\n",
    "El código de estas operaciónes se muestran acomtinuación:\n",
    "\n",
    "* Creación del atributo `dt_time`:\n",
    "\n",
    "    ```python\n",
    "    uber=pd.read_csv('nyc_uber_2014.csv')\n",
    "    uber=uber.rename(columns ={'Date/Time':'dt_time'})\n",
    "    uber['dt_split']=uber.dt_time.str.split('/')\n",
    "    ```\n",
    "    \n",
    " \n",
    "* Construcción del _Dataset_ **uber_n**, para **n** igual al mes correspondiente:\n",
    "\n",
    "    ```python\n",
    "    uber['month'] = uber.dt_time.str[0].astype(int)\n",
    "    uber_n=uber[uber['month']==n]\n",
    "    uber_n.drop(['dt_split','month'],axis=1).to_csv('uber_n.csv',sep=',', index=0)\n",
    "    ```\n",
    "\n",
    "Lo siguiente será cargar cada uno de estos _Dataframes_ para poder trabajr con ellos. Desúés se realizará un procedimiento para no tener que cargar los _Datasets_ individualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber4=pd.read_csv('uber_4.csv')\n",
    "uber5=pd.read_csv('uber_5.csv')\n",
    "uber6=pd.read_csv('uber_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber cargado los _Dataset_ en variables individuales es hora de utilizar `pd.concat()` que resivirá, como parámetros, una lista con cada una de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dt_time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>6/1/2014 6:27:00</td>\n",
       "      <td>40.7554</td>\n",
       "      <td>-73.9738</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>6/1/2014 6:35:00</td>\n",
       "      <td>40.7543</td>\n",
       "      <td>-73.9817</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>6/1/2014 6:37:00</td>\n",
       "      <td>40.7751</td>\n",
       "      <td>-73.9633</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>6/1/2014 6:46:00</td>\n",
       "      <td>40.6952</td>\n",
       "      <td>-74.1784</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>6/1/2014 6:51:00</td>\n",
       "      <td>40.7621</td>\n",
       "      <td>-73.9817</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           dt_time      Lat      Lon    Base\n",
       "94          94  6/1/2014 6:27:00  40.7554 -73.9738  B02512\n",
       "95          95  6/1/2014 6:35:00  40.7543 -73.9817  B02512\n",
       "96          96  6/1/2014 6:37:00  40.7751 -73.9633  B02512\n",
       "97          97  6/1/2014 6:46:00  40.6952 -74.1784  B02512\n",
       "98          98  6/1/2014 6:51:00  40.7621 -73.9817  B02512"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_concat=pd.concat([uber4,uber5,uber6])\n",
    "row_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinación de atributos.\n",
    "\n",
    "Para el siguiente ejemplo necesitamos crear dos _Datasets_ a partir de `ebola_melt`, `ebola_melt2` y `status_country`. \n",
    "\n",
    "La atarea es unir estos dos _Datasets_, con varios atributos, en uno solo. Necesitamos usar el método `concat` cuyos parámetros son: una lista con los _Dataframes_ y el parámetro `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_melt2=ebola_melt.iloc[:,0:3]\n",
    "status_country=ebola_melt.iloc[:,5:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuevo _Dataframe_ se llamará **ebola_tidy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>type_country</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day  type_country   type country\n",
       "0    1/5/2015  289  Cases_Guinea  Cases  Guinea\n",
       "1    1/4/2015  288  Cases_Guinea  Cases  Guinea\n",
       "2    1/3/2015  287  Cases_Guinea  Cases  Guinea\n",
       "3    1/2/2015  286  Cases_Guinea  Cases  Guinea\n",
       "4  12/31/2014  284  Cases_Guinea  Cases  Guinea"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola_tidy=pd.concat([ebola_melt2,status_country], axis=1)\n",
    "ebola_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busqueda y concatenación de patrones.\n",
    "\n",
    "#### Coicidencia de patrones.\n",
    "\n",
    "En ocaciones es necesario concatenar una gran variedad de archivos o _Datasets_. Realizarlo manualmente sería una tarea poco funcional. \n",
    "\n",
    "Sin embargo _Python_ nos provee de funciones que nos ayudan a realizar estas tareas de una manera outomatizada.\n",
    "\n",
    "<br>\n",
    "<blockquote>\n",
    "    <p style=\"font-style: italic; color:#737373; text-align:justify\"> &mdash; El módulo glob busca las rutas de archivos que hagna coicidir con una serie de caracteres (wildcarts) parecidas al de \"shell\" en UNix como *,?,etc,etc... &mdash;\n",
    "</p>\n",
    "</blockquote><div style=\"text-align:right; width:100%\"><cite style=\"font-style: italic; color:#737373; text-align:right\">– Manual de Python...</cite></div>\n",
    "<br>    \n",
    "</div>\n",
    "</font>\n",
    "\n",
    "En el ejercicio anterior donde teníamos que cargar los diferentes _Datasets_ de **UBER** para cada uno de los meses, y con ellos poder construir un solo _Dataframe_, era necesario cargar uno por uno. Pero si quisiéramos realizar la concatenación de diferentes _Datasets_ sin tener que hacerlo uno por uno basta con realizar los siguientes pasos:\n",
    "\n",
    "* Asegurarse que la función **glob** este cargada para poder trabajar con ella.\n",
    "\n",
    "* Creamos una nueva variable llamada **pattern** que alojará, en una cadena y acompañado del wildcart `*` más el patron de archivos que agrupará. Por ejemplo `uber*.csv`.\n",
    "\n",
    "* Los nombres de los diferentes archivos serán guardados en una lista. Para ello es necesario utilizar el método `.glob` de la función `glob()`. Ejmplo `csv_files = glob.glob(pattern)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "pattern = 'uber*.csv'\n",
    "csv_files = glob.glob(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí hemos podido indicarle a _Python_ que es necesario que agrupe todos archovos de formato `.csv` por que queremos realizar una unión de todos ellos. Ahora solo resta ingresar a cada uno de los nombres para corroborar que todos se encuentren cargados y listos para usarse.\n",
    "\n",
    "```python\n",
    "print(csv_files)\n",
    "['uber_4.csv', 'uber_5.csv', 'uber_6.csv']\n",
    "```\n",
    "\n",
    "Para acceder a uno de llos es necesario ejecutar la consulta de la siguiente manera:\n",
    "\n",
    "```python\n",
    "some_csv=pd.read_csv(csv_files[index])\n",
    "some_csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dt_time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5/1/2014 0:02:00</td>\n",
       "      <td>40.7521</td>\n",
       "      <td>-73.9914</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5/1/2014 0:06:00</td>\n",
       "      <td>40.6965</td>\n",
       "      <td>-73.9715</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5/1/2014 0:15:00</td>\n",
       "      <td>40.7464</td>\n",
       "      <td>-73.9838</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7463</td>\n",
       "      <td>-74.0011</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9734</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           dt_time      Lat      Lon    Base\n",
       "0           0  5/1/2014 0:02:00  40.7521 -73.9914  B02512\n",
       "1           1  5/1/2014 0:06:00  40.6965 -73.9715  B02512\n",
       "2           2  5/1/2014 0:15:00  40.7464 -73.9838  B02512\n",
       "3           3  5/1/2014 0:17:00  40.7463 -74.0011  B02512\n",
       "4           4  5/1/2014 0:17:00  40.7594 -73.9734  B02512"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_csv=pd.read_csv(csv_files[1])\n",
    "uber_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteración y concaqtenación\n",
    "\n",
    "Ahora que ya tenemos una lista de _Datasets_ para poder utilizar podemos realizar un loop, como anteriromente, habíamos planteado para poder unirlos y no tener que definirlos uno por uno para que podamos juntarlos.\n",
    "\n",
    "* En primer lugar necesitamos una lista vacia para poder iterar a cada archivo **.csv**. La llamaremos `frames = []`\n",
    "\n",
    "* Después creamos el loop para poder iterar a cada uno de los archivos. Ejemplo:\n",
    "\n",
    "```python\n",
    "for iter in frames:\n",
    "    DataFrame=pd.read_csv(iter)\n",
    "    frames.append(DataFrame)\n",
    "uber=pd.concat(frames)\n",
    "```\n",
    "\n",
    "Como podemos observar el loop realizará la extracción, la lectura y la concatenación de todos los archivos por nocotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dt_time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>6/1/2014 0:40:00</td>\n",
       "      <td>40.7610</td>\n",
       "      <td>-73.6035</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>5/1/2014 4:41:00</td>\n",
       "      <td>40.7695</td>\n",
       "      <td>-73.9621</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>6/1/2014 1:38:00</td>\n",
       "      <td>40.7392</td>\n",
       "      <td>-73.9953</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9734</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>6/1/2014 2:03:00</td>\n",
       "      <td>40.7408</td>\n",
       "      <td>-74.0079</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>4/1/2014 5:24:00</td>\n",
       "      <td>40.7393</td>\n",
       "      <td>-73.9974</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>4/1/2014 5:56:00</td>\n",
       "      <td>40.7442</td>\n",
       "      <td>-73.9854</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>4/1/2014 6:25:00</td>\n",
       "      <td>40.7382</td>\n",
       "      <td>-74.0033</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>6/1/2014 2:19:00</td>\n",
       "      <td>40.7195</td>\n",
       "      <td>-73.9887</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>5/1/2014 5:29:00</td>\n",
       "      <td>40.6951</td>\n",
       "      <td>-74.1784</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>6/1/2014 1:56:00</td>\n",
       "      <td>40.7295</td>\n",
       "      <td>-74.0084</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>4/1/2014 4:47:00</td>\n",
       "      <td>40.7234</td>\n",
       "      <td>-73.9974</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>6/1/2014 2:51:00</td>\n",
       "      <td>40.6564</td>\n",
       "      <td>-73.6453</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>6/1/2014 6:27:00</td>\n",
       "      <td>40.7554</td>\n",
       "      <td>-73.9738</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>4/1/2014 3:35:00</td>\n",
       "      <td>40.7389</td>\n",
       "      <td>-74.0393</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>4/1/2014 6:48:00</td>\n",
       "      <td>40.7271</td>\n",
       "      <td>-74.0054</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>4/1/2014 4:49:00</td>\n",
       "      <td>40.7336</td>\n",
       "      <td>-73.9900</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>5/1/2014 5:05:00</td>\n",
       "      <td>40.7137</td>\n",
       "      <td>-73.9631</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>6/1/2014 6:24:00</td>\n",
       "      <td>40.7615</td>\n",
       "      <td>-73.9881</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>5/1/2014 4:25:00</td>\n",
       "      <td>40.7753</td>\n",
       "      <td>-73.9904</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           dt_time      Lat      Lon    Base\n",
       "30          30  6/1/2014 0:40:00  40.7610 -73.6035  B02512\n",
       "57          57  5/1/2014 4:41:00  40.7695 -73.9621  B02512\n",
       "52          52  6/1/2014 1:38:00  40.7392 -73.9953  B02512\n",
       "4            4  5/1/2014 0:17:00  40.7594 -73.9734  B02512\n",
       "57          57  6/1/2014 2:03:00  40.7408 -74.0079  B02512\n",
       "35          35  4/1/2014 5:24:00  40.7393 -73.9974  B02512\n",
       "52          52  4/1/2014 5:56:00  40.7442 -73.9854  B02512\n",
       "72          72  4/1/2014 6:25:00  40.7382 -74.0033  B02512\n",
       "61          61  6/1/2014 2:19:00  40.7195 -73.9887  B02512\n",
       "77          77  5/1/2014 5:29:00  40.6951 -74.1784  B02512\n",
       "56          56  6/1/2014 1:56:00  40.7295 -74.0084  B02512\n",
       "28          28  4/1/2014 4:47:00  40.7234 -73.9974  B02512\n",
       "70          70  6/1/2014 2:51:00  40.6564 -73.6453  B02512\n",
       "94          94  6/1/2014 6:27:00  40.7554 -73.9738  B02512\n",
       "19          19  4/1/2014 3:35:00  40.7389 -74.0393  B02512\n",
       "92          92  4/1/2014 6:48:00  40.7271 -74.0054  B02512\n",
       "29          29  4/1/2014 4:49:00  40.7336 -73.9900  B02512\n",
       "65          65  5/1/2014 5:05:00  40.7137 -73.9631  B02512\n",
       "92          92  6/1/2014 6:24:00  40.7615 -73.9881  B02512\n",
       "53          53  5/1/2014 4:25:00  40.7753 -73.9904  B02512"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[]\n",
    "for csv in csv_files:\n",
    "    df=pd.read_csv(csv)\n",
    "    frames.append(df)\n",
    "uber=pd.concat(frames)\n",
    "uber.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cruce de datos (Merge).\n",
    "\n",
    "\n",
    "La concatenación no es el único método que se puede utilizar a la hora de combinar datos. Sobre todo cuando el atributo que deseamos concatenar no tiene el mísmo orden en ambos atributos del _Datasets_. \n",
    "\n",
    "`.merge()` es una función que le permite a _Pandas_ poder realizar el cruce de datos, con base en un atributo presente en ambos _Datasets_, de manera similar que con _SQL_. La consulta se llevaría a cabo con los siguientes parámetros:\n",
    "\n",
    "* `left=dataset` y `rigth=dataset` ambos deberán contener el mismo atributo y pueden tener, o no, el mismo nombre.\n",
    "\n",
    "* `on=None` se utiliza cuando el atributo objetivo aparece con el mismo nombre en ambos _Datasets_. Si no el valor será `None`.\n",
    "\n",
    "* `left_on='atribute_a'` & `rigth_on='atribute_b'` cuando el atributo objetivo aparece, en ambos datasets, con diferente nombre.\n",
    "\n",
    "Existen diferentes maneras de realizar un _join_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge 1-to-1.\n",
    "\n",
    "Imaginemos que necesitamos realizar el cruze de la información de dos _Datasets_ `visited` & `site`. Si observamos, en ambas columnas, existe un atributo que comparten ambas tablas pero con diferente nombre. Uno es `name` en el _Dataset_ `site` y otro es `site` en el _Dataset_ `site`. El resultado es necesario guardarlo en un nuevo _Dataset_ llamada **o2o**.\n",
    "\n",
    "Para poder cruzar los datos en el atributo que tienen en particualr ambas tablas la línea sería: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long  ident   site       dated\n",
       "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
       "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
       "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = pd.read_csv('site.csv')\n",
    "visited = pd.read_csv('visited.csv')\n",
    "o2o=pd.merge(left=site, right=visited, on=None, left_on='name', right_on='site')\n",
    "o2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge many to one (one to many).\n",
    "\n",
    "Cuando se tienen registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>844</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1932-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long  ident   site       dated\n",
       "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
       "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
       "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
       "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
       "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
       "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
       "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
       "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_visited=pd.read_csv('dup_visited.csv')\n",
    "m2o = pd.merge(left=site,right=dup_visited, left_on='name',right_on='site')\n",
    "m2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge many to many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident  site       dated\n",
       "0    619  DR-1  1927-02-08\n",
       "1    622  DR-1  1927-02-10\n",
       "2    734  DR-3  1939-01-07\n",
       "3    735  DR-3  1930-01-12\n",
       "4    751  DR-3  1930-02-26"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey=pd.read_csv('dup_visited.csv')\n",
    "survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "      <th>taken</th>\n",
       "      <th>person</th>\n",
       "      <th>quant</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "      <td>619</td>\n",
       "      <td>dyer</td>\n",
       "      <td>rad</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "      <td>619</td>\n",
       "      <td>dyer</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "      <td>622</td>\n",
       "      <td>dyer</td>\n",
       "      <td>rad</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "      <td>622</td>\n",
       "      <td>dyer</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>844</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1932-03-22</td>\n",
       "      <td>844</td>\n",
       "      <td>roe</td>\n",
       "      <td>rad</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "      <td>734</td>\n",
       "      <td>pb</td>\n",
       "      <td>sal</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "      <td>734</td>\n",
       "      <td>lake</td>\n",
       "      <td>rad</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "      <td>734</td>\n",
       "      <td>pb</td>\n",
       "      <td>temp</td>\n",
       "      <td>-21.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "      <td>735</td>\n",
       "      <td>pb</td>\n",
       "      <td>rad</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>temp</td>\n",
       "      <td>-26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "      <td>751</td>\n",
       "      <td>pb</td>\n",
       "      <td>rad</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "      <td>751</td>\n",
       "      <td>pb</td>\n",
       "      <td>temp</td>\n",
       "      <td>-18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "      <td>751</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>rad</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>lake</td>\n",
       "      <td>temp</td>\n",
       "      <td>-16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>roe</td>\n",
       "      <td>sal</td>\n",
       "      <td>41.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "      <td>837</td>\n",
       "      <td>lake</td>\n",
       "      <td>rad</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "      <td>837</td>\n",
       "      <td>lake</td>\n",
       "      <td>sal</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "      <td>837</td>\n",
       "      <td>roe</td>\n",
       "      <td>sal</td>\n",
       "      <td>22.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name    lat    long  ident   site       dated  taken person quant  \\\n",
       "0    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   rad   \n",
       "1    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   sal   \n",
       "2    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   rad   \n",
       "3    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   sal   \n",
       "4    DR-1 -49.85 -128.57    844   DR-1  1932-03-22    844    roe   rad   \n",
       "5    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb   sal   \n",
       "6    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734   lake   rad   \n",
       "7    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb  temp   \n",
       "8    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735     pb   rad   \n",
       "9    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN   sal   \n",
       "10   DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN  temp   \n",
       "11   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb   rad   \n",
       "12   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb  temp   \n",
       "13   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751   lake   sal   \n",
       "14   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   rad   \n",
       "15   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   sal   \n",
       "16   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake  temp   \n",
       "17   DR-3 -47.15 -126.72    752   DR-3         NaN    752    roe   sal   \n",
       "18  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   rad   \n",
       "19  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   sal   \n",
       "20  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837    roe   sal   \n",
       "\n",
       "    reading  \n",
       "0      9.82  \n",
       "1      0.13  \n",
       "2      7.80  \n",
       "3      0.09  \n",
       "4     11.25  \n",
       "5      8.41  \n",
       "6      0.05  \n",
       "7    -21.50  \n",
       "8      7.22  \n",
       "9      0.06  \n",
       "10   -26.00  \n",
       "11     4.35  \n",
       "12   -18.50  \n",
       "13     0.10  \n",
       "14     2.19  \n",
       "15     0.09  \n",
       "16   -16.00  \n",
       "17    41.60  \n",
       "18     1.46  \n",
       "19     0.21  \n",
       "20    22.50  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey=pd.read_csv('survey.csv')\n",
    "m2m = pd.merge(left=m2o, right=survey, left_on='ident', right_on='taken')\n",
    "m2m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips de datos.\n",
    "\n",
    "#### Conversión entre tipos de datos.\n",
    "\n",
    "En muchas ocaciones es necesario realizar la conversión entre diferentes tipos de datos. El tipo de dato `object` es el tipo de dato que _Python_ utiliza para codificar caracteres. Los atributos numéricos pueden ser transformados a caracteres y viceversa. El método `astype()` nos ayuda a realizar la conversión.\n",
    "\n",
    "Por lo general cuando leemos _Datasets_ damos por hecho que cada uno de los atributos que estámos cargando son los correctos. En otras ocasiones necesaitamos cambiar el tipo de dato, en uno o varios atributos, para poder trabajar con sus datos. El parámetro, de la fucnión `read_csv`, que me permite realizar esto es `dtype = {'atribute1':select_dtype,'atrubute2':select_dtype,...}`.\n",
    "\n",
    "Para efectos de este ejercicio leeremos el archivo **tups.csv** para el cual es necesario cambiar el tipo de dato a los atributos `total_bill` y `tip`. Después chequemos la información con la fucnión `info()` para observar los diferentes tipos de datos de los atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   total_bill  244 non-null    object\n",
      " 1   tip         244 non-null    object\n",
      " 2   sex         244 non-null    object\n",
      " 3   smoker      244 non-null    object\n",
      " 4   day         244 non-null    object\n",
      " 5   time        244 non-null    object\n",
      " 6   size        244 non-null    int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tips=pd.read_csv('tips.csv', dtype={'total_bill':object,'tip':object} )\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra de las ventajas de hacer cambios en los tipos de datos es el ganar memoria. En algunos casos el tipo de dato que presenta un atributo no es el más funcional para nuestro análisis. Por ejemplo; el mejor tipo de dato para el atributo  `sex` o `smoker` sería `'category'` en lugar de `object`.\n",
    "\n",
    "Podemos realizar el cambio utilizando la función `astype()` y el argumento `'category'`. Si de nueva cuenta checamos la información del _Dataset_ para observar los cambios, además de reducir el tamaño de uso en emoria de `13.4+ KB` a `10.3+ KB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   total_bill  244 non-null    object  \n",
      " 1   tip         244 non-null    object  \n",
      " 2   sex         244 non-null    category\n",
      " 3   smoker      244 non-null    category\n",
      " 4   day         244 non-null    object  \n",
      " 5   time        244 non-null    object  \n",
      " 6   size        244 non-null    int64   \n",
      "dtypes: category(2), int64(1), object(4)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "tips.sex = tips.sex.astype('category')\n",
    "tips.smoker=tips.smoker.astype('category')\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulación de caracteres.\n",
    "\n",
    "#### Empate de caracteres con expresiones regulares.\n",
    "\n",
    "La mayoría de los _Datasets_ están construidos por caracteres. Es por eso que su manipulación se vuelve de suma importancia para pocer hacer consistente nuestros datos y poder trabajr con ellos.\n",
    "\n",
    "_Python_ proporciona herramientas para poder manipular caracteres, como el modulo `re` (expresiones regulares o regex) cuyo trabajo es empatar secuencias de caracteres. Es parecida al modulo `glob` y las _wildcarts_. \n",
    "\n",
    "A continuación ejemplificaremos alguas secuencias de caracteres y sus correspondientes expresiones regulares::\n",
    "\n",
    "* `17` cantidades con datos de tipo entero pueden ser reemplazados por la expresión regular: `\\d*`.\n",
    "\n",
    "* `$17` para empatar cantidades como la anterior, pero con el signo `$`, son equivalentes a colocar: `\\$\\d*`.\n",
    "\n",
    "* `$17.00` números enteros, con \"n\" cantidad de decimales, son equivalentes a tener: `\\$\\d*\\.\\d*`.\n",
    "\n",
    "* `$1234567.12 ` esta catidad contiene muchos dígitos, y después del punto decimal solo dos. Podemos localizar estas cantidades: `\\$\\d*\\.\\d{2}`\n",
    "\n",
    "* `$1234567.123` con cantidades de más de 3 dígitos la consulta debería de ser así: `^\\$\\d*\\.\\{2}$`\n",
    "\n",
    "* Utilizamos `[A-Z]` para hallar mayúsculas, seguida de `\\w*` que busca \"n\" cantidad de datos alfanuméricos en una cadena. \n",
    "\n",
    "Averiguemos si, es posible saber si dado el formato de un código de la forma `xxx-xxx-xxx` coincide si ingresamos un código manualmente. Para ello utilizamos el modulo `re` y su método `compile` quien alojará el formato del código de caracteres. El metodo `match` realiza la comparación y nos regresa un resultado de tipo _Booleano_.\n",
    "\n",
    "Probemos con dos códigos: `1123-456-7890` y `123-456-7890`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "prog = re.compile('xxx-xxx-xxxx')\n",
    "result = prog.match('123-456-7890')\n",
    "result2 = prog.match('123-456-7890')\n",
    "print(bool(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción de valores numéricos desde caracteres.\n",
    "\n",
    "Esta tarea es, a menudo, muy realizada. En la siguiente cadena: `la receta lleva 10 fesas y 1 platano` nos interesa extraer los valores `10` y `1`. Cuando necesitamos extraer valores con varios, donde los caracterers corresponden a varios patrones de coincidencias, la fucnión `findall()` nos es de gran ayuda. Esta nos regresa, en una lista, todas las coincidencias que hayamos indicado encontrar.\n",
    "\n",
    "Entonces `\\d` nos ayuda a encontrar números. Esta _regex_ es precedida de `+` para que se repita varias veces la búsqueda. Esto nos asegura que el número `10` es visualizado como un número solo y no la combinación de `1` y `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '1']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.findall('\\d+', 'la receta lleva 10 fesas y 1 platano')\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento para el formato de un número telefónico de la forma `xxx-xxx-xxx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "pattern1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento, en una cadena de caracteres, números con el formato de dos cifras decimales `$123.45`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern2 = bool(re.match(pattern='\\$\\d*\\.\\d{2}', string='$123.45'))\n",
    "pattern2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coincidencia de letras mayúsculas en la palabra `Australia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern3 = bool(re.match(pattern='[A-Z]\\w*', string='Australia'))\n",
    "pattern3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rutinas para la limpieza de datos\n",
    "\n",
    "Podemos automatizar la limpieza en un _Dataset_ programando rutinas que hacen eficiente este proceso. Por ejemplo; el _Dataset_ **nan.csv** contiene 5 columnas donde se alojan records de tipo `NaN`.\n",
    "\n",
    "Nuestro trabajo será propgramar una rutina que: pueda reconocer si un redord, en una de las columnas del _Dataset_ **nan.csv**, es menor que `3` lo pueda etiquetar como `Malo`. Si es mayor o igual a `3` lo pueda etiquetar como `Bueno`. Pero si no cumple con ninguna de las condiciones anteriores lo pueda etiquetar como `No aplicó`.\n",
    "\n",
    "Para este ejercico necesitamos crear el _Dataset_ con valores random y para poder trabajar con el siguiente código;\n",
    "\n",
    "```python\n",
    "np.random.seed(123)\n",
    "data = np.random.randint(0, 10, (10,5))\n",
    "df_nan = pd.DataFrame(data, columns=list('abcde'))\n",
    "df_nan = df.where(df > 2)\n",
    "df_nan.to_csv('nan.csv', sep=',', index=False)\n",
    "```\n",
    "La sintaxis de la función que llamaremos como `look` necesita la siguiente estructura;\n",
    "\n",
    "```python\n",
    "# Definimos la función 'function_name' con el parámetro 'par':\n",
    "def function_name(par):\n",
    "\n",
    "    # Regresa 'respuesta' cuando condición:\n",
    "    if condición :\n",
    "        return 'Respuesta'\n",
    "    \n",
    "    # Regresa 'Bueno' cuando condición:\n",
    "    elif condición:\n",
    "        return 'Respuesta'\n",
    "    \n",
    "    # Cuando no se cumpla ninguna de las condiciones:    \n",
    "    else:\n",
    "        return 'Respuesta'\n",
    "\n",
    "# Alicamos la función creando una columna al dataframe:\n",
    "df['new_colum'] = df.column.apply(function_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>columna_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d    e   columna_a\n",
       "0  NaN  NaN  6.0  NaN  3.0  $No aplicó\n",
       "1  9.0  6.0  NaN  NaN  NaN       Bueno\n",
       "2  9.0  NaN  NaN  9.0  3.0       Bueno\n",
       "3  4.0  NaN  NaN  4.0  NaN       Bueno\n",
       "4  7.0  3.0  NaN  4.0  7.0       Bueno\n",
       "5  NaN  4.0  8.0  NaN  7.0  $No aplicó\n",
       "6  9.0  3.0  4.0  6.0  NaN       Bueno\n",
       "7  5.0  6.0  NaN  NaN  8.0       Bueno\n",
       "8  3.0  5.0  NaN  NaN  6.0        Malo\n",
       "9  NaN  4.0  4.0  6.0  3.0  $No aplicó"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_look=pd.read_csv('nan.csv')\n",
    "def look(val):\n",
    "\n",
    "    if val <= 3:\n",
    "        return 'Malo'\n",
    "    \n",
    "    elif val >3:\n",
    "        return 'Bueno'\n",
    "    \n",
    "    else:\n",
    "        return '$No aplicó'\n",
    "    \n",
    "df_look['columna_a'] = df_look.a.apply(look)\n",
    "df_look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que en el nuevo _Dataframe_, la columna `columna_a`, contiene records `$No aplicó`. Ahora supongamos que necesitamos limpiar esos records, pero en lugar de hacerlo como en el paso anterior nos apoyaremos con la función `replace()` y con la ayuda de la construcción de una función **lambda**. \n",
    "\n",
    "Las funciones **lambda** tienen la siguiente sintaxis:\n",
    "\n",
    "```python\n",
    "df['new_column'] = df.column.apply(lambda iter: iter.replace('$', ''))\n",
    "```\n",
    "donde `iter` es nuestro valor para iterar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>columna_a</th>\n",
       "      <th>nueva_columna_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d    e   columna_a nueva_columna_a\n",
       "0  NaN  NaN  6.0  NaN  3.0  $No aplicó       No aplicó\n",
       "1  9.0  6.0  NaN  NaN  NaN       Bueno           Bueno\n",
       "2  9.0  NaN  NaN  9.0  3.0       Bueno           Bueno\n",
       "3  4.0  NaN  NaN  4.0  NaN       Bueno           Bueno\n",
       "4  7.0  3.0  NaN  4.0  7.0       Bueno           Bueno\n",
       "5  NaN  4.0  8.0  NaN  7.0  $No aplicó       No aplicó\n",
       "6  9.0  3.0  4.0  6.0  NaN       Bueno           Bueno\n",
       "7  5.0  6.0  NaN  NaN  8.0       Bueno           Bueno\n",
       "8  3.0  5.0  NaN  NaN  6.0        Malo            Malo\n",
       "9  NaN  4.0  4.0  6.0  3.0  $No aplicó       No aplicó"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_look['nueva_columna_a'] = df_look.columna_a.apply(lambda x: x.replace('$', ''))\n",
    "df_look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajar con valores duplicados y valores de tipo \"NaN\".\n",
    "\n",
    "#### Eliminación de valores duplicados.\n",
    "\n",
    "Trabajar con valores duplicados puede traernos varios inconvenientes. Ocupan especio extra en la memoria y pueden producir errores en nuestros cálculos. \n",
    "_**Pandas**_ nos provee de funciones que nos ayudan a la eliminación de estos valores. Para este ejercicio crearemos un nuevo _Dataframe_ llamado **df_lookrep** con algunos valores repetidos. EL objetivo será eliminar estos registros aplicandole el método `drop_duplicates()`. \n",
    "\n",
    "Según la información del tataframe **df_look** debemos tener un total de 10 renglones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>columna_a</th>\n",
       "      <th>nueva_columna_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b    c    d    e   columna_a nueva_columna_a\n",
       "0   NaN  NaN  6.0  NaN  3.0  $No aplicó       No aplicó\n",
       "1   9.0  6.0  NaN  NaN  NaN       Bueno           Bueno\n",
       "2   9.0  NaN  NaN  9.0  3.0       Bueno           Bueno\n",
       "3   4.0  NaN  NaN  4.0  NaN       Bueno           Bueno\n",
       "4   7.0  3.0  NaN  4.0  7.0       Bueno           Bueno\n",
       "5   NaN  4.0  8.0  NaN  7.0  $No aplicó       No aplicó\n",
       "6   9.0  3.0  4.0  6.0  NaN       Bueno           Bueno\n",
       "7   5.0  6.0  NaN  NaN  8.0       Bueno           Bueno\n",
       "8   3.0  5.0  NaN  NaN  6.0        Malo            Malo\n",
       "9   NaN  4.0  4.0  6.0  3.0  $No aplicó       No aplicó\n",
       "10  NaN  NaN  6.0  NaN  3.0  $No aplicó       No aplicó\n",
       "11  9.0  6.0  NaN  NaN  NaN       Bueno           Bueno\n",
       "12  9.0  NaN  NaN  9.0  3.0       Bueno           Bueno\n",
       "13  4.0  NaN  NaN  4.0  NaN       Bueno           Bueno\n",
       "14  7.0  3.0  NaN  4.0  7.0       Bueno           Bueno\n",
       "15  NaN  4.0  8.0  NaN  7.0  $No aplicó       No aplicó\n",
       "16  9.0  3.0  4.0  6.0  NaN       Bueno           Bueno\n",
       "17  5.0  6.0  NaN  NaN  8.0       Bueno           Bueno\n",
       "18  3.0  5.0  NaN  NaN  6.0        Malo            Malo\n",
       "19  NaN  4.0  4.0  6.0  3.0  $No aplicó       No aplicó\n",
       "20  NaN  NaN  6.0  NaN  3.0  $No aplicó       No aplicó\n",
       "21  9.0  6.0  NaN  NaN  NaN       Bueno           Bueno\n",
       "22  9.0  NaN  NaN  9.0  3.0       Bueno           Bueno\n",
       "23  4.0  NaN  NaN  4.0  NaN       Bueno           Bueno\n",
       "24  7.0  3.0  NaN  4.0  7.0       Bueno           Bueno\n",
       "25  NaN  4.0  8.0  NaN  7.0  $No aplicó       No aplicó\n",
       "26  9.0  3.0  4.0  6.0  NaN       Bueno           Bueno\n",
       "27  5.0  6.0  NaN  NaN  8.0       Bueno           Bueno\n",
       "28  3.0  5.0  NaN  NaN  6.0        Malo            Malo\n",
       "29  NaN  4.0  4.0  6.0  3.0  $No aplicó       No aplicó"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookrep = pd.concat([df_look]*3, ignore_index=True)\n",
    "df_lookrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se podrá ver el _Dataframe_ **clean_dflook** volverá a tener los mismos renglones que en un principio tenia **df_look**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>columna_a</th>\n",
       "      <th>nueva_columna_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Malo</td>\n",
       "      <td>Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$No aplicó</td>\n",
       "      <td>No aplicó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d    e   columna_a nueva_columna_a\n",
       "0  NaN  NaN  6.0  NaN  3.0  $No aplicó       No aplicó\n",
       "1  9.0  6.0  NaN  NaN  NaN       Bueno           Bueno\n",
       "2  9.0  NaN  NaN  9.0  3.0       Bueno           Bueno\n",
       "3  4.0  NaN  NaN  4.0  NaN       Bueno           Bueno\n",
       "4  7.0  3.0  NaN  4.0  7.0       Bueno           Bueno\n",
       "5  NaN  4.0  8.0  NaN  7.0  $No aplicó       No aplicó\n",
       "6  9.0  3.0  4.0  6.0  NaN       Bueno           Bueno\n",
       "7  5.0  6.0  NaN  NaN  8.0       Bueno           Bueno\n",
       "8  3.0  5.0  NaN  NaN  6.0        Malo            Malo\n",
       "9  NaN  4.0  4.0  6.0  3.0  $No aplicó       No aplicó"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dflook=df_lookrep.drop_duplicates()\n",
    "clean_dflook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elinación de valores de tipo \"NaN\".\n",
    "\n",
    "Es muy raro trabajar con datasets que no contengan algún tipo de _missing values_. Se debe tener en cuenta la naturalesa de nuestros datos o su origen para posteriormente tomar las correctas desiciones para poder trabajr con ellos. SObre todo poer que en muchos casos los cálculos no aceptan este tipo de records.\n",
    "\n",
    "El método `fillna()` nos ayuda a trabajar con los atributos y sustituir estos registros por cualquier otro valor que nosotros necesitemos. Por ejemplo; el _Dataset_ **airquality** tiene un total de **153** registros, pero en el atributo `Ozone` tenemos **116**. Lo cual indica que de alguna manera existen records de tipo `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Ozone    116 non-null    float64\n",
      " 1   Solar.R  146 non-null    float64\n",
      " 2   Wind     153 non-null    float64\n",
      " 3   Temp     153 non-null    int64  \n",
      " 4   Month    153 non-null    int64  \n",
      " 5   Day      153 non-null    int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.3 KB\n"
     ]
    }
   ],
   "source": [
    "airquality.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a sustiruir estos records con el valor del promedio del atributo `Ozone`. Para ello necesitaremos ayuda del método `.mean()`. Nuestro nuevos cálculos serán alojados en el mismo _Dataframe_ y en el msimo atributo llamado `Ozone`. Al terminar veremos en la información, del nuevo _Dataset_, que el nuevo valor para el atributo `Ozone` será de **153**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Ozone    153 non-null    float64\n",
      " 1   Solar.R  146 non-null    float64\n",
      " 2   Wind     153 non-null    float64\n",
      " 3   Temp     153 non-null    int64  \n",
      " 4   Month    153 non-null    int64  \n",
      " 5   Day      153 non-null    int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.3 KB\n"
     ]
    }
   ],
   "source": [
    "oz_mean=airquality.Ozone.mean()\n",
    "airquality['Ozone']=airquality.Ozone.fillna(oz_mean)\n",
    "airquality.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación en _Datasets_ con \"assest\".\n",
    "\n",
    "Esta rutina nos ayudará a verificar si existen records de tipo (`NaN`) en todos los atributos de un _Dataset_. Para ello nos apoyaremos de dos métodos más: `notnull()` y `all()`. `assert` es la función que evaluará esta rutina.\n",
    "\n",
    "**Nota: podemos utilizar el equivalente que es pd.notnull(df)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos entonces: ¿qué atributos contienen registros `NaN` o `missing values` en el _Dataset_ **ebola**?.. Estos serán etiquetados con `False` en caso de ser así. De momento no abordaremos la explicación del método `all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    True\n",
       "Day                     True\n",
       "Cases_Guinea           False\n",
       "Cases_Liberia          False\n",
       "Cases_SierraLeone      False\n",
       "Cases_Nigeria          False\n",
       "Cases_Senegal          False\n",
       "Cases_UnitedStates     False\n",
       "Cases_Spain            False\n",
       "Cases_Mali             False\n",
       "Deaths_Guinea          False\n",
       "Deaths_Liberia         False\n",
       "Deaths_SierraLeone     False\n",
       "Deaths_Nigeria         False\n",
       "Deaths_Senegal         False\n",
       "Deaths_UnitedStates    False\n",
       "Deaths_Spain           False\n",
       "Deaths_Mali            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(ebola).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gran parte de este _Dataframe_ contiene records de tipo `NaN`. Para este ejercicio utilizaremos el método `fillna()` para sustituirlos por `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Cases_Guinea</th>\n",
       "      <th>Cases_Liberia</th>\n",
       "      <th>Cases_SierraLeone</th>\n",
       "      <th>Cases_Nigeria</th>\n",
       "      <th>Cases_Senegal</th>\n",
       "      <th>Cases_UnitedStates</th>\n",
       "      <th>Cases_Spain</th>\n",
       "      <th>Cases_Mali</th>\n",
       "      <th>Deaths_Guinea</th>\n",
       "      <th>Deaths_Liberia</th>\n",
       "      <th>Deaths_SierraLeone</th>\n",
       "      <th>Deaths_Nigeria</th>\n",
       "      <th>Deaths_Senegal</th>\n",
       "      <th>Deaths_UnitedStates</th>\n",
       "      <th>Deaths_Spain</th>\n",
       "      <th>Deaths_Mali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10030.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>8166.0</td>\n",
       "      <td>9722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>8115.0</td>\n",
       "      <td>9633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>3471.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3/26/2014</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3/25/2014</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3/24/2014</td>\n",
       "      <td>2</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3/22/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \\\n",
       "0      1/5/2015  289        2776.0            0.0            10030.0   \n",
       "1      1/4/2015  288        2775.0            0.0             9780.0   \n",
       "2      1/3/2015  287        2769.0         8166.0             9722.0   \n",
       "3      1/2/2015  286           0.0         8157.0                0.0   \n",
       "4    12/31/2014  284        2730.0         8115.0             9633.0   \n",
       "..          ...  ...           ...            ...                ...   \n",
       "117   3/27/2014    5         103.0            8.0                6.0   \n",
       "118   3/26/2014    4          86.0            0.0                0.0   \n",
       "119   3/25/2014    3          86.0            0.0                0.0   \n",
       "120   3/24/2014    2          86.0            0.0                0.0   \n",
       "121   3/22/2014    0          49.0            0.0                0.0   \n",
       "\n",
       "     Cases_Nigeria  Cases_Senegal  Cases_UnitedStates  Cases_Spain  \\\n",
       "0              0.0            0.0                 0.0          0.0   \n",
       "1              0.0            0.0                 0.0          0.0   \n",
       "2              0.0            0.0                 0.0          0.0   \n",
       "3              0.0            0.0                 0.0          0.0   \n",
       "4              0.0            0.0                 0.0          0.0   \n",
       "..             ...            ...                 ...          ...   \n",
       "117            0.0            0.0                 0.0          0.0   \n",
       "118            0.0            0.0                 0.0          0.0   \n",
       "119            0.0            0.0                 0.0          0.0   \n",
       "120            0.0            0.0                 0.0          0.0   \n",
       "121            0.0            0.0                 0.0          0.0   \n",
       "\n",
       "     Cases_Mali  Deaths_Guinea  Deaths_Liberia  Deaths_SierraLeone  \\\n",
       "0           0.0         1786.0             0.0              2977.0   \n",
       "1           0.0         1781.0             0.0              2943.0   \n",
       "2           0.0         1767.0          3496.0              2915.0   \n",
       "3           0.0            0.0          3496.0                 0.0   \n",
       "4           0.0         1739.0          3471.0              2827.0   \n",
       "..          ...            ...             ...                 ...   \n",
       "117         0.0           66.0             6.0                 5.0   \n",
       "118         0.0           62.0             0.0                 0.0   \n",
       "119         0.0           60.0             0.0                 0.0   \n",
       "120         0.0           59.0             0.0                 0.0   \n",
       "121         0.0           29.0             0.0                 0.0   \n",
       "\n",
       "     Deaths_Nigeria  Deaths_Senegal  Deaths_UnitedStates  Deaths_Spain  \\\n",
       "0               0.0             0.0                  0.0           0.0   \n",
       "1               0.0             0.0                  0.0           0.0   \n",
       "2               0.0             0.0                  0.0           0.0   \n",
       "3               0.0             0.0                  0.0           0.0   \n",
       "4               0.0             0.0                  0.0           0.0   \n",
       "..              ...             ...                  ...           ...   \n",
       "117             0.0             0.0                  0.0           0.0   \n",
       "118             0.0             0.0                  0.0           0.0   \n",
       "119             0.0             0.0                  0.0           0.0   \n",
       "120             0.0             0.0                  0.0           0.0   \n",
       "121             0.0             0.0                  0.0           0.0   \n",
       "\n",
       "     Deaths_Mali  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "..           ...  \n",
       "117          0.0  \n",
       "118          0.0  \n",
       "119          0.0  \n",
       "120          0.0  \n",
       "121          0.0  \n",
       "\n",
       "[122 rows x 18 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ebolafill=ebola.fillna(0)\n",
    "df_ebolafill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, si ejecutamos de nueva cuenta `pd.notnull(Dataframe).all()` observaremos que todos los atributos tienen records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   True\n",
       "Day                    True\n",
       "Cases_Guinea           True\n",
       "Cases_Liberia          True\n",
       "Cases_SierraLeone      True\n",
       "Cases_Nigeria          True\n",
       "Cases_Senegal          True\n",
       "Cases_UnitedStates     True\n",
       "Cases_Spain            True\n",
       "Cases_Mali             True\n",
       "Deaths_Guinea          True\n",
       "Deaths_Liberia         True\n",
       "Deaths_SierraLeone     True\n",
       "Deaths_Nigeria         True\n",
       "Deaths_Senegal         True\n",
       "Deaths_UnitedStates    True\n",
       "Deaths_Spain           True\n",
       "Deaths_Mali            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(df_ebolafill).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `all()` nos devuelve `True` cuando todos los registros en una consulta son `True`. Cuando se usa `all()`, en un _Dataframe_, para cada uno de los atributos se devuelve una seríe de registros _Booleanos_ (`False` o `True`). Por eso es necesario encadenarlo a otro método `all()`, de nueva cuenta, para que solo regrese `True` si todos los registros en los atributos fueron _True_. \n",
    "\n",
    "De esta manera es como podemos verificar que todos los records de un _Dataset_ no contienen valores `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pd.notnull(df_ebolafill).all().all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
